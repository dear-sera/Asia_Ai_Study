{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scrapy_day2.ipynb",
      "provenance": [],
      "mount_file_id": "1hyBm0HlVAGUA5mEAzIvfDZVtQ38aMCgo",
      "authorship_tag": "ABX9TyPmsVhxHNNZneNW0vJZ1ioU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sera0911/asia-ai-study/blob/main/scrapy_day2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6B8_4e6AwZq"
      },
      "source": [
        "scrapy_day1 정리    \n",
        "\n",
        "csv 파일 형식으로 저장된 데이터를 실행중인 파이썬프로그램의 메로리로 로딩 :   \n",
        "pandas.read_csv(csv 파일, sep = , index_col=, header =, names =, encoding = ,skiprows=, nrows= , dtype) : DataFrame이라는 객체로 반환   \n",
        "(index_col이걸 쓰면 위치도 반환가능,header와 nammes는 비슷하다 이름을 알려줌, encoding은 파일이 깨지는 걸 막기위해서,  skiprows특정 행을 건너뛰기 위해, nrows n개의 줄만 반환, dtype d타입으로 반환해라)     \n",
        "\n",
        "\n",
        "2차원 구조의 데이터를 csv파일로 저장 :   \n",
        "to_csv(객체, 저장할 파일경로 이름, endcoding=)   \n",
        "\n",
        "\n",
        "DataFrame 객체의 데이터 구조 정보를 제공: info()    \n",
        "\n",
        "javascript object notation(JSON) 데이터들을 객체로 만들어주는 형식   \n",
        "JSON 데이터는 메모리에 로딩, 파일에 저장,로딩   \n",
        "파이썬 객체 -> 변환 -> JSON 객체 : 직렬화해서 파일, 메모리에 저장     \n",
        "= json.demp(), json.dumps(파이썬객체, index=, sort_keys=)       \n",
        "JSON 객체  -> 변환 ->  파이썬 객체 : 역직렬화(직렬화된 JSON객체를 파이썬 객체로 복원) \n",
        "= json.load(), loads()    \n",
        "\n",
        "\n",
        "\n",
        "xml(메타 데이터 + 데이터) 데이터를 읽고 쓰는 기능을 제공하는 라이브러리중에서    \n",
        "xml(메타 데이터 + 데이터) 데이터 문자열을 => xml파서가 객체들의 트리 구조로 생성(fromstring메서드를 사용해서)    \n",
        "xlrd패키지 xml.etree.ElementTree.fromstring() => xml객체 트리로부터 find('엘리먼트명').txt로 값을 추출    \n",
        "\n",
        "엘리먼트명=태그명    \n",
        "\n",
        "\n",
        "excel 파일 형식에 저장된 데이터 읽고 쓰기   \n",
        "pandas.read_excel()     \n",
        "\n",
        "\n",
        "웹에서 데이터를 가져오려면 url을 새용해서 요청 보내고, 응답(html형태의 텍스트)으로 받아야 한다.(요청이 없으면 응답이 없다)   \n",
        "파이썬 프로그램에서 url요청에 대한 응답을 받아오려면 urlib.request.urlopen(url).read().decode('인코딩')   \n",
        "\n",
        "인코딩은 보통 utf8을 쓰지만 아니라면 decode를 사용   \n",
        "\n",
        "urllib 패키지 - request모듈,     \n",
        "                parse 모듈 - url(도메인, 포트, path, context, resorce, parameter)을 조작,   \n",
        "                error 모듈  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2ytabTTRkBO"
      },
      "source": [
        "Ø requests 모듈   \n",
        "§ 웹페이지에서 HTTP 요청을 보내 원하는 HTML 정보를 가져오는 모듈   \n",
        "§ 간편하게 HTTP request를 보낼 수 있음   \n",
        "§ 세션을 유지하기가 용이함   \n",
        "§ python2 , python3을 완벽하게 지원   \n",
        "§ 코드가 간결하고 documentation이 잘 되어 있음   \n",
        "§ HTTP GET, POST, PUT, DELETE 등을 사용할 수 있으며, 편리한 데이타 인코딩 기능을 제공    \n",
        "§ 데이타를 Dictionary로 만들어 GET, POST 등에서 사용하면 필요한 Request 인코딩을 자동으로 처리해 준다.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpS1e2EKSADM",
        "outputId": "f731bf20-918d-407c-ef67-dbe4555608a8"
      },
      "source": [
        "import requests\n",
        "\n",
        "# GET 헤더부분에 포함되서 넘어감\n",
        "resp = requests.get('http://httpbin.org/get')\n",
        "print(resp.text)\n",
        "print(type(resp))\n",
        "\n",
        "\n",
        "# POST 바디부분에 포함되서 넘어감\n",
        "dic = {\"id\": 1, \"name\": \"Kim\", \"age\": 10}\n",
        "resp = requests.post('http://httpbin.org/post', data=dic)\n",
        "print(resp.text)\n",
        "print(type(resp))\n",
        "\n",
        "\n",
        "resp = requests.put('http://httpbin.org/put')\n",
        "print(resp.text)\n",
        "print(type(resp))\n",
        "\n",
        "resp = requests.delete('http://httpbin.org/delete')\n",
        "print(resp.text)\n",
        "print(type(resp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"args\": {}, \n",
            "  \"headers\": {\n",
            "    \"Accept\": \"*/*\", \n",
            "    \"Accept-Encoding\": \"gzip, deflate\", \n",
            "    \"Host\": \"httpbin.org\", \n",
            "    \"User-Agent\": \"python-requests/2.23.0\", \n",
            "    \"X-Amzn-Trace-Id\": \"Root=1-605bfd86-0c6d3ac277811d072d00ac12\"\n",
            "  }, \n",
            "  \"origin\": \"34.91.14.222\", \n",
            "  \"url\": \"http://httpbin.org/get\"\n",
            "}\n",
            "\n",
            "<class 'requests.models.Response'>\n",
            "{\n",
            "  \"args\": {}, \n",
            "  \"data\": \"\", \n",
            "  \"files\": {}, \n",
            "  \"form\": {\n",
            "    \"age\": \"10\", \n",
            "    \"id\": \"1\", \n",
            "    \"name\": \"Kim\"\n",
            "  }, \n",
            "  \"headers\": {\n",
            "    \"Accept\": \"*/*\", \n",
            "    \"Accept-Encoding\": \"gzip, deflate\", \n",
            "    \"Content-Length\": \"20\", \n",
            "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
            "    \"Host\": \"httpbin.org\", \n",
            "    \"User-Agent\": \"python-requests/2.23.0\", \n",
            "    \"X-Amzn-Trace-Id\": \"Root=1-605bfd86-4b5bd69242dfe57142bca961\"\n",
            "  }, \n",
            "  \"json\": null, \n",
            "  \"origin\": \"34.91.14.222\", \n",
            "  \"url\": \"http://httpbin.org/post\"\n",
            "}\n",
            "\n",
            "<class 'requests.models.Response'>\n",
            "{\n",
            "  \"args\": {}, \n",
            "  \"data\": \"\", \n",
            "  \"files\": {}, \n",
            "  \"form\": {}, \n",
            "  \"headers\": {\n",
            "    \"Accept\": \"*/*\", \n",
            "    \"Accept-Encoding\": \"gzip, deflate\", \n",
            "    \"Content-Length\": \"0\", \n",
            "    \"Host\": \"httpbin.org\", \n",
            "    \"User-Agent\": \"python-requests/2.23.0\", \n",
            "    \"X-Amzn-Trace-Id\": \"Root=1-605bfd86-1aa1bcb47d7afb8a0c0da8cc\"\n",
            "  }, \n",
            "  \"json\": null, \n",
            "  \"origin\": \"34.91.14.222\", \n",
            "  \"url\": \"http://httpbin.org/put\"\n",
            "}\n",
            "\n",
            "<class 'requests.models.Response'>\n",
            "{\n",
            "  \"args\": {}, \n",
            "  \"data\": \"\", \n",
            "  \"files\": {}, \n",
            "  \"form\": {}, \n",
            "  \"headers\": {\n",
            "    \"Accept\": \"*/*\", \n",
            "    \"Accept-Encoding\": \"gzip, deflate\", \n",
            "    \"Content-Length\": \"0\", \n",
            "    \"Host\": \"httpbin.org\", \n",
            "    \"User-Agent\": \"python-requests/2.23.0\", \n",
            "    \"X-Amzn-Trace-Id\": \"Root=1-605bfd86-396bbd8703bd0d3158bf1d7f\"\n",
            "  }, \n",
            "  \"json\": null, \n",
            "  \"origin\": \"34.91.14.222\", \n",
            "  \"url\": \"http://httpbin.org/delete\"\n",
            "}\n",
            "\n",
            "<class 'requests.models.Response'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddAMRgzMSDID"
      },
      "source": [
        "http 응답코드 메소드는 get  post 방식이 아니여도 put  delete 방식도 사용할 수 있다       \n",
        "get 요청받은 url의 정보를 검색해서 응답한다\n",
        "head get과 동일하지만, 응답에 바디가 없고 응답코드와 헤드만 응답    \n",
        "post 요청된 자원을 생성한다    \n",
        "put 웹에 요청된 자원을 업데이트한다    \n",
        "delete 요청된 자원을 삭제 할 것(안정성때문에 보통 서버에서 비활성화)     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHvKi3geWBvg"
      },
      "source": [
        "§ GET 요청할 때 parameter 전달    \n",
        "§ POST 요청할 때 data 전달"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1pamuV7WMS7"
      },
      "source": [
        "§ 헤더 , 쿠키 추가    \n",
        "쿠키란? 내가 정보를 get하거나 post 시에 나에게 번호(표)를 주게 되어(내가 누구란 걸 의미) 내 브라우저에 자동적으로 저장되는 데 다음에 같은 서버에 또 요청을 보낼때마다 자동으로 쿠키 정보까지 같이 본내준다.   \n",
        "하지만 파이썬은 브라우저와 다르게 자동으로 저장되거나 보내주지 않아서 쿠키를 입력해야한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzA9yenyWKGL"
      },
      "source": [
        "import requests\n",
        "headers = {'Content-Type': 'application/json; charset=utf-8'}\n",
        "cookies = {'session_id': 'sorryidontcare'}\n",
        "res = requests.get(URL, headers=headers, cookies=cookies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTDyZAWIZCxE"
      },
      "source": [
        "Response객체의 속성   \n",
        "content : 바이너리 원문 응답   \n",
        "json : 응답 데이터가 JSON 포멧인 경우 사전    \n",
        "raise_for_status Response에서 에러가 있을 경우 프로그램을 중단시키는 메서드      \n",
        "status_code : 응답 객체의 상태 코드(200, 500 등등)    \n",
        "text : UTF-8로 인코딩된 문자열 응답      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZZb2lanXFzG"
      },
      "source": [
        "Ø Responses 객체    \n",
        "§ requests.get(url) - 해당 웹페이지 호출 결과를 가진 Response 객체를 리턴    \n",
        "§ status_code 속성 - HTTP Status 결과를 체크할 수 있다    \n",
        "§ text 속성 - Response 에서 리턴된 데이타를 문자열로 리턴, str 클래스 타입, requests 모듈에서 자동으로 데이타를 인코딩해 준다.   \n",
        "(requests는 HTTP 헤더를 통해 결과 데이타의 인코딩 방식을 추측하여 Response 객체의encoding 속성에 그 값을 지정하고, text 속성을 엑세스할 때 이 encoding 속성을 사용한다. 만약 인코딩 방식을\n",
        "변경해야 한다면, text 속성을 읽기 전에 Response의 encoding 속성을 변경하면 된다.)    \n",
        "§ content 속성 - Response 데이타를 바이트(bytes)로 리턴    \n",
        "§ raise_for_status() - 만약 Response에서 에러가 있을 경우 프로그램을 중단시키는 메서드    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VNIvzInZYVN",
        "outputId": "2c6faef3-7c4c-4a6d-afd1-4c754750d105"
      },
      "source": [
        "resp = requests.get('http://naver.com') # 네이버 홈\n",
        "print(resp.encoding)\n",
        "\n",
        "resp = requests.get('http://finance.naver.com') # 증권\n",
        "print(resp.encoding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UTF-8\n",
            "EUC-KR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oBJOq1Oafia"
      },
      "source": [
        "BeautifulSoup   \n",
        "Ø BeautifulSoup 모듈   \n",
        "§ HTML과 XML 문서의 파싱(가공되지 않은 문자열에서 필요한 부분을 추출하여 의미있는 구조화된 데이터로 만드는 과정)을 도와주는 강력한 python 라이브러리   \n",
        "§ equest.text를 이용해 가져온 텍스트형태의 html 데이터에서 어떻게 원하는 html 요소에 접근을 도와주는 라이브러리    \n",
        "§ 태그 간 모든 상하적이고 수평적인 관계에서 일관된 접근 방식을 사용.    \n",
        "§ BeautifulSoup 객체 - 마크업 문자열, 마크업 파일, 웹에 있는 마크업 문서에 연결된 URL로부터 생성 가능    \n",
        "\n",
        "\n",
        "§ 태그 간 모든 상하적이고 수평적인 관계에서 일관된 접근 방식을 사용한다.   \n",
        "§ 태그 간 관계는 태그 객체의 속성으로 표현한다    \n",
        "\n",
        "\n",
        "태그 t의 부모요소는 t.parent    \n",
        "태그 t의 다음 태그는 t.next,    \n",
        "태그 t의 바로 전 태그는 t.prev,    \n",
        "태그 t의 자식 태그(태그 안의 태그)는 t.children   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW9vn5VUfaPZ"
      },
      "source": [
        "Ø BeautifulSoup 모듈    \n",
        "§ urlopen 함수를 사용하여 원하는 주소로부터 웹페이지를 가져온 후, BeautifulSoup 객체로 변환    \n",
        "§ BeautifulSoup 객체 - 웹문서를 파싱한 상태로서 태그 별로 분해되어 태그로 구성된 트리 구조 상태   \n",
        " html.parser 파서 종류가 4종인데 기본이 html파서"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe7Y26YvgZzz"
      },
      "source": [
        "# 문자열에서 soup을 생성한다.\n",
        "soup1 = BeautifulSoup(\"<HTML><HEAD><header></HEAD><body></HTML>\")\n",
        "\n",
        "# 로컬 파일에서 soup을 생성한다.\n",
        "soup2 = BeautifulSoup(open(\"myDoc.html\"))\n",
        "\n",
        "# 웹 문서에서 soup을 생성한다.\n",
        "# urlopen()이 \"http://\"를 자동으로 추가하지 않는다는 것 주의!\n",
        "soup3 = BeautifulSoup(urlopen(\"http://www.networksciencelab.com/\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpVXROO0grm-"
      },
      "source": [
        "Ø 마크업 파서(markup parser)    \n",
        "§ 파싱이란 일련의 문자열로 구성된 문서를 의미 있는 토큰(token)으로 분해하고 토큰으로 구성된 파스 트리(parse tree)를 만드는 것입니다.    \n",
        "§ 마크업 파서(markup parser) - HTML 태그와 내용을 추출하는 파이썬 컴포넌트, BeautifulSoup객체 생성자의 두 번째 옵션 인수    \n",
        "html.parser 기본옵션으로 빠르지만 유연하지 않다. 단순 html문서에 사용   \n",
        "lxml 매우빠르고 유연   \n",
        "xml xml파일에만 사용  \n",
        "html5lib 느리지만, 유연함함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p23axYD-hD14"
      },
      "source": [
        "Ø BeautifulSoup 모듈    \n",
        "• 루트 요소인 <html>에서 마침표(.)를 사용해 값에 접근"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaZgq0hwhDE-",
        "outputId": "f0b773cc-c9f1-43bb-a943-6bda34044a53"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "# 분석하고 싶은 HTML\n",
        "html = \"\"\"\n",
        "<html><body>\n",
        "<h1>스크레이핑이란?</h1>\n",
        "<p>웹 페이지를 분석하는 것</p>\n",
        "<p>원하는 부분을 추출하는 것</p>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "# HTML 분석하기\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "# 원하는 부분 추출하기\n",
        "h1 = soup.html.body.h1  #루트태그가 html 자식태그가 body\n",
        "p1 = soup.html.body.p\n",
        "p2 = p1.next_sibling.next_sibling   #next_sibling.next_sibling 두 번 들어가는 건 그 사이에  화이트스페이스라는 공백이 있기 때문\n",
        "# 요소의 글자 출력하기\n",
        "print(\"h1 = \" + h1.string)    #.string h1 내부 속성을 문자열로 출력하기 위해선 .string을 사용함\n",
        "print(\"p = \" + p1.string)\n",
        "print(\"p = \" + p2.string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h1 = 스크레이핑이란?\n",
            "p = 웹 페이지를 분석하는 것\n",
            "p = 원하는 부분을 추출하는 것\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VEUPKPdifi2"
      },
      "source": [
        "• 태그는 이름(name), 속성(attribute), 속성값(value)로 구성된다.    \n",
        "• find()로 이름, 속성, 속성값을 특정하여 태그를 찾을 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyqDRK7LiMeB",
        "outputId": "3553ba32-ccaa-4a3b-b7a2-f7724b724165"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = \"\"\"\n",
        "<html><body>\n",
        " <h1 id=\"title\">스크레이핑이란?</h1>\n",
        " <p id=\"body\">웹 페이지를 분석하는 것</p>\n",
        " <p>원하는 부분을 추출하는 것</p>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "# HTML 분석하기\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# find() 메서드로 원하는 부분 추출하기\n",
        "title = soup.find(id=\"title\")\n",
        "body = soup.find(id=\"body\")   \n",
        "#body = soup.find('p')   \n",
        "\n",
        "# 텍스트 부분 출력하기\n",
        "print(\"#title=\" + title.string)\n",
        "print(\"#body=\" + body.string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#title=스크레이핑이란?\n",
            "#body=웹 페이지를 분석하는 것\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VmYM1vIjzec"
      },
      "source": [
        "• find_all() : 여러 개의 태그를 한 번에 추출   \n",
        "• 태그의 속성은 attrs 속성에서 추출   \n",
        "• 태그 내부의 내용(텍스트)는 string 속성으로 추출   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHd4wjJSj0py",
        "outputId": "dc6f5330-7720-4d96-bf3d-7ecec95e470a"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "html = \"\"\"\n",
        "<html><body>\n",
        " <ul>    #언오더드 리스트\n",
        "  <li><a href=\"http://www.naver.com\">naver</a></li>  #오더드리스트 \n",
        "  <li><a href=\"http://www.daum.net\">daum</a></li>\n",
        " </ul>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "# HTML 분석하기\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "# find_all() 메서드로 추출하기\n",
        "links = soup.find_all(\"a\")     #find_all 모든 앵커태그를 한 번에 가져옴\n",
        "# 링크 목록 출력하기\n",
        "for a in links:    #집합객체에서 하나씩 뽑아냄\n",
        "  href = a.attrs['href']   #attrs= atrributes = 태그의 속성을 뽑아낸다 \n",
        "  text = a.string\n",
        "  print(text, \">\", href)   #text는 내용을 출력 href는 ul을 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naver > http://www.naver.com\n",
            "daum > http://www.daum.net\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh7VQLP-k5Cn"
      },
      "source": [
        "§ 마크업 문서에 연결된 URL로부터 BeautifulSoup 객체 생성    \n",
        "BeautifulSoup 객체의 생성자 첫번째 인수 - open() 함수 또는 urllib.request.urlopen()함수의 리턴 값을 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMzWqor2exTJ",
        "outputId": "7fcd7523-94b0-4d43-80ca-20f5b8050f92"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request as req\n",
        "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
        "# urlopen()으로 데이터 가져오기\n",
        "res = req.urlopen(url)\n",
        "# BeautifulSoup으로 분석하기\n",
        "soup = BeautifulSoup(res, \"html.parser\")   \n",
        "# 원하는 데이터 추출하기\n",
        "title = soup.find(\"title\").string   #태그와 태그 사이 내용을 뽑아 출력\n",
        "wf = soup.find(\"wf\").string\n",
        "print(title)\n",
        "print(wf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "기상청 육상 중기예보\n",
            "○ (강수) 28일(일) 오전에 전국에 비가 오겠습니다. 30일(화)은 제주도에 비가 오겠습니다.<br />          4월 1일(목) 제주도에 다시 비가 시작되어 4월 2일(금) 전남권과 경남권, 제주도에 비가 오겠습니다.<br />○ (기온) 이번 예보기간의 아침 기온은 3~14도로 어제(24일, 1~11도)보다 높겠고, 낮 기온은 12~22도로 어제(24일, 14~21도)와 비슷하겠습니다.<br />          한편, 29일(월)~4월 1일(목) 내륙을 중심으로 일교차가 크겠으니, 환절기 건강관리에 유의하기 바랍니다.<br />○ (해상) 28일(일)은 제주도해상과 남해동부해상, 동해상에서 물결이 2.0~4.0m로 매우 높게 일겠습니다.<br />○ (주말전망) 27일(토) 오후부터 28일(일) 오전 사이 전국에 비가 오겠습니다. 아침 기온은 4~14도, 낮 기온은 12~22도가 되겠습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTFWAMM3lvOu"
      },
      "source": [
        "§ BeautifulSoup.prettify() - 마크업 문서를 읽기 쉬운 형태로 출력    \n",
        "§ BeautifulSoup.get_text() - 마크업 문서에서 모든 태그를 제거하고 텍스트 부분만 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "JayH-cfMlyH0",
        "outputId": "db5d0489-bd98-45bd-b2cc-f64d65349508"
      },
      "source": [
        "htmlString = ''' <HTML>\n",
        " <HEAD><TITLE>My document</TITLE></HEAD>\n",
        " <BODY>Main text.</BODY></HTML>'''\n",
        "Soup = BeautifulSoup(htmlString)\n",
        "print(Soup.get_text())\n",
        "Soup.prettify()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "My document\n",
            "Main text.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<html>\\n <head>\\n  <title>\\n   My document\\n  </title>\\n </head>\\n <body>\\n  Main text.\\n </body>\\n</html>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nj0J2vA3_5e"
      },
      "source": [
        "§ BeautifulSoup 모듈에서는 파이썬 딕셔너리 인터페이스로 HTML 태그 속성에 접근할 수 있다   \n",
        "\n",
        "객체 t가 <a href=\"foobar.html> 인 경우 링크의 문자열 값 추출 => t[\"href\"].string   \n",
        " H2 태그로 된 모든 인스턴스 추출 => BeautifulSoup.find_all(\"H2\")    \n",
        "볼드나 이탤릭 포맷으로 된 모든 인스턴스 추출 => BeautifulSoup.find_all([\"i\", \"b\", \"em\", \"strong\"])    \n",
        "속성(id=\"link3\" 같은)을 가진 태그 추출 =>    \n",
        "BeautifulSoup.find(id=\"link3\")    \n",
        "첫 번째 하이퍼링크의 링크 추출 =>   \n",
        " links = soup.find_all(\"a\")      \n",
        "firstLink = links[0][\"href\"]     \n",
        "또는 딕셔너리 구문이나 tag.get() 함수 사용    \n",
        "firstLink = links[0].get(\"href\")     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SId6oLBO4bFq"
      },
      "source": [
        "§ 태그를 추출하기 전에 tag.has_attr() 함수를 사용해서 속성이 존재하는지 꼭 확인    \n",
        "왜? 오류가 발생하는지 확인하기 위해서"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCs0YwsF4e3e",
        "outputId": "94808fd0-b1a3-4979-ad21-ea97742fcac9"
      },
      "source": [
        "import urllib.request as req\n",
        "with req.urlopen(\"http://www.networksciencelab.com/\") as doc:\n",
        "  soup = BeautifulSoup(doc)\n",
        "\n",
        "links = [(link.string, link[\"href\"]) for link in soup.find_all(\"a\") if link.has_attr(\"href\")]\n",
        "print(links)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(None, 'https://pragprog.com/book/dzpyds/data-science-essentials-in-python'), (None, 'https://pragprog.com/book/dzcnapy/complex-network-analysis-in-python'), ('DZPYDS', 'https://www.amazon.com/gp/product/1680501844'), ('DZCNAPY', 'https://www.amazon.com/gp/product/1680502697'), ('Networks of Music Groups as Success Predictors', 'http://www.slideshare.net/DmitryZinoviev/networks-of-music-groups-as-success-predictors'), ('Network Science Workshop', 'http://www.slideshare.net/DmitryZinoviev/workshop-20212296'), ('Resilience in Transaction-Oriented Networks', 'http://www.slideshare.net/DmitryZinoviev/resilience-in-transactional-networks'), ('Peer Ratings in Massive Online Social Networks', 'http://www.slideshare.net/DmitryZinoviev/peer-ratings-in-massive-online-social-networks'), ('Semantic Networks of Interests in Online NSSI Communities', 'http://www.slideshare.net/DmitryZinoviev/presentation-31680572'), ('Towards an Ideal Store', 'http://www.slideshare.net/DmitryZinoviev/10-monthsymposiumbeta'), ('D.Zinoviev, \"Analyzing Cultural Domains with Python,\"', 'https://media.pragprog.com/newsletters/2016-04-06.html'), ('D. Zinoviev, D. Stefanescu, G. Fireman, and L. Swenson, \"Semantic networks of interests in online non-suicidal self-injury communities,\"', 'http://dhj.sagepub.com/content/2/2055207616642118.full'), ('D.Zinoviev, \"The Pain of Complexity,\"', 'http://www.mitpressjournals.org/doi/abs/10.1162/LEON_a_01271#.VzOvwHUrKzc'), ('D.Zinoviev, Z.Zhu, and K.Li, \"Building mini-categories in product networks,\"', 'http://link.springer.com/chapter/10.1007/978-3-319-16112-9_18'), ('D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Mitigation of delayed management costs in transaction-oriented systems,\"', 'http://arxiv.org/abs/1409.6771'), ('D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Simulating resilience in transaction-oriented networks,\"', 'http://dl.acm.org/citation.cfm?id=2499974'), ('D.Zinoviev, D.Stefanescu, L.Swenson, and G.Fireman, \"Semantic networks of interests in online NSSI communities,\"', 'http://arxiv.org/abs/1206.5520'), ('D.Zinoviev and S.Llewelyn, \"Co-Evolution of Friendship and Publishing in Online Blogging Social Networks,\"', 'http://arxiv.org/abs/1401.6964'), ('D.Zinoviev, \"Information diffusion in social networks,\"', 'http://dl.acm.org/citation.cfm?id=2208181'), ('D.Zinoviev and V.Duong, \"A game theoretical approach to broadcast  information diffusion in social networks,\"', 'http://dl.acm.org/citation.cfm?id=2048377'), ('D.Zinoviev and V.Duong, \"A game theoretical approach to modeling full-duplex information dissemination,\"', 'http://dl.acm.org/citation.cfm?id=1999462'), ('D.Zinoviev, V.Duong, and H.Zhang, \"A game theoretical approach to modeling information dissemination in social networks,\"', 'http://arxiv.org/abs/1006.5493'), ('D.Zinoviev and V.Duong, \"Toward Understanding Friendship in Online Social Networks,\"', 'http://arxiv.org/abs/0902.4658'), ('D.Zinoviev, \"Topology and Geometry of Online Social Networks,\"', 'http://arxiv.org/abs/0807.3996'), ('Vixi: The Game of Meaning', '/vixi/html5/'), ('Evgenia Cherkasova', 'http://meaningoflife.cherkasova.org/'), ('All Characters from War and Peace by L.Tolstoy', 'v2.jpg'), ('Mapping the Bible: Social Networks in the Holy Book', 'bible-networks.pdf'), ('FIFA World Cup 2014: Who Beat Whom?', 'wc2014.gif'), ('The seed post \"9 American habits I lost when I moved to Germany\" and its 125 \"likes\" and \"shares\" on Facebook', 'facebook_spread.gif'), ('Email', 'mailto:dzinoviev@suffolk.edu'), ('Suffolk University', 'https://www.suffolk.edu/academics/faculty/z/i/dmitry-zinoviev'), ('Google Scholar', 'https://scholar.google.com/citations?hl=en&user=j5GjuIkAAAAJ&sortby=pubdate&view_op=list_works&pagesize=100'), ('LinkedIn', 'https://www.linkedin.com/pub/dmitry-zinoviev/4/a78/27b'), ('Academia.edu', 'https://suffolk.academia.edu/DmitryZinoviev'), ('ResearchGate', 'https://www.researchgate.net/profile/Dmitry_Zinoviev')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3GpsxNU44cx"
      },
      "source": [
        "§ 자바스크립트 라이브러리인 jQuery처럼 CSS 선택자를 지정해서 원하는 요소를 추출하는 기능 제공   \n",
        "§ select는 CSS selector로 tag 객체를 찾아 반환   \n",
        "CSS → 시각적인 디자인과 레이아웃 표현    \n",
        "선택자→ 선택을 해주는 요소, 특정 요소들을 선택하여 스타일을 적용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPzNpUrE69nv"
      },
      "source": [
        "메서드                      설명\n",
        "soup.select_one(선택자)    CSS 선택자로 요소 하나를 추출    \n",
        "soup.select(<선택자>)      CSS 선택자로 요소 여러 개를 리스트로 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ8ndel47HNN",
        "outputId": "fd7dac0a-2483-4d7b-eda0-ccba69b6e4a6"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "# 분석 대상 HTML\n",
        "html = \"\"\"\n",
        "<html><body>\n",
        "<div id=\"meigen\">    \n",
        " <h1>위키북스 도서</h1>\n",
        " <ul class=\"items\">\n",
        "  <li>유니티 게임 이펙트 입문</li>\n",
        "  <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
        "  <li>모던 웹사이트 디자인의 정석</li>\n",
        " </ul>\n",
        "</div>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# HTML 분석하기\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "# 필요한 부분을 CSS 쿼리로 추출하기\n",
        "# 타이틀 부분 추출하기\n",
        "h1 = soup.select_one(\"div#meigen > h1\").string   #하나의 div태그를 가져오는데  #샵은 id를 뜻하고 h1의 내용을 가져오라는 것\n",
        "print(\"h1 =\", h1)\n",
        "# 목록 부분 추출하기\n",
        "li_list = soup.select(\"div#meigen > ul.items > li\") #자식태그인 ul태그안에 아이템즈= 내용을 가져오되 그 안에 li태그를 가져와라\n",
        "for li in li_list:\n",
        "  print(\"li =\", li.string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h1 = 위키북스 도서\n",
            "li = 유니티 게임 이펙트 입문\n",
            "li = 스위프트로 시작하는 아이폰 앱 개발 교과서\n",
            "li = 모던 웹사이트 디자인의 정석\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWMEvGBA-LYt"
      },
      "source": [
        "§ 연습문제- 네이버 금융에서 환율 정보 추출하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPBemNXW-NsE",
        "outputId": "d8fca3bc-e890-474d-80c9-c062b4d95252"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request as req\n",
        "# HTML 가져오기\n",
        "url = \"https://finance.naver.com/marketindex/\"\n",
        "res = req.urlopen(url)\n",
        "# HTML 분석하기\n",
        "soup = BeautifulSoup(res, \"html.parser\")\n",
        "# 원하는 데이터 추출하기\n",
        "price = soup.find(id=\"exchangeList\").find(\"div\").find(\"span\").string\n",
        "print('usd/krw =', price)\n",
        "\n",
        "price2 = soup.select_one(\"div.head_info > span.value\").string\n",
        "print('usd/krw =', price2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usd/krw = 1,133.50\n",
            "usd/krw = 1,133.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqJgO8jrCy7i"
      },
      "source": [
        "§  연습문제 - 위키 문헌에 공개돼 있는 윤동주 작가의 작품 목록 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OI-j-XkC4GM",
        "outputId": "7ecdbc79-377c-4670-e12a-a295c1e3e57e"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request as req\n",
        "# 뒤의 인코딩 부분은 \"저자:윤동주\"라는 의미입니다.\n",
        "# 따로 입력하지 말고 위키 문헌 홈페이지에 들어간 뒤에 주소를 복사해서 사용하세요.\n",
        "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
        "res = req.urlopen(url)\n",
        "soup = BeautifulSoup(res, \"html.parser\")\n",
        "# #mw-content-text 바로 아래에 있는\n",
        "# ul 태그 바로 아래에 있는\n",
        "# li 태그 아래에 있는\n",
        "# a 태그를 모두 선택합니다.\n",
        "a_list = soup.select(\"#mw-content-text > div > ul > li a\")\n",
        "for a in a_list:\n",
        "  name = a.string\n",
        "  print(\"-\", name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- 하늘과 바람과 별과 시\n",
            "- 증보판\n",
            "- 서시\n",
            "- 자화상\n",
            "- 소년\n",
            "- 눈 오는 지도\n",
            "- 돌아와 보는 밤\n",
            "- 병원\n",
            "- 새로운 길\n",
            "- 간판 없는 거리\n",
            "- 태초의 아침\n",
            "- 또 태초의 아침\n",
            "- 새벽이 올 때까지\n",
            "- 무서운 시간\n",
            "- 십자가\n",
            "- 바람이 불어\n",
            "- 슬픈 족속\n",
            "- 눈감고 간다\n",
            "- 또 다른 고향\n",
            "- 길\n",
            "- 별 헤는 밤\n",
            "- 흰 그림자\n",
            "- 사랑스런 추억\n",
            "- 흐르는 거리\n",
            "- 쉽게 씌어진 시\n",
            "- 봄\n",
            "- 참회록\n",
            "- 간(肝)\n",
            "- 위로\n",
            "- 팔복\n",
            "- 못자는밤\n",
            "- 달같이\n",
            "- 고추밭\n",
            "- 아우의 인상화\n",
            "- 사랑의 전당\n",
            "- 이적\n",
            "- 비오는 밤\n",
            "- 산골물\n",
            "- 유언\n",
            "- 창\n",
            "- 바다\n",
            "- 비로봉\n",
            "- 산협의 오후\n",
            "- 명상\n",
            "- 소낙비\n",
            "- 한난계\n",
            "- 풍경\n",
            "- 달밤\n",
            "- 장\n",
            "- 밤\n",
            "- 황혼이 바다가 되어\n",
            "- 아침\n",
            "- 빨래\n",
            "- 꿈은 깨어지고\n",
            "- 산림\n",
            "- 이런날\n",
            "- 산상\n",
            "- 양지쪽\n",
            "- 닭\n",
            "- 가슴 1\n",
            "- 가슴 2\n",
            "- 비둘기\n",
            "- 황혼\n",
            "- 남쪽 하늘\n",
            "- 창공\n",
            "- 거리에서\n",
            "- 삶과 죽음\n",
            "- 초한대\n",
            "- 산울림\n",
            "- 해바라기 얼굴\n",
            "- 귀뚜라미와 나와\n",
            "- 애기의 새벽\n",
            "- 햇빛·바람\n",
            "- 반디불\n",
            "- 둘 다\n",
            "- 거짓부리\n",
            "- 눈\n",
            "- 참새\n",
            "- 버선본\n",
            "- 편지\n",
            "- 봄\n",
            "- 무얼 먹구 사나\n",
            "- 굴뚝\n",
            "- 햇비\n",
            "- 빗자루\n",
            "- 기왓장 내외\n",
            "- 오줌싸개 지도\n",
            "- 병아리\n",
            "- 조개껍질\n",
            "- 겨울\n",
            "- 트루게네프의 언덕\n",
            "- 달을 쏘다\n",
            "- 별똥 떨어진 데\n",
            "- 화원에 꽃이 핀다\n",
            "- 종시\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH3oa8LUH4hC"
      },
      "source": [
        "§ CSS 선택자로 추출 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpAUvZgPIFcZ"
      },
      "source": [
        "<ul id=\"bible\">\n",
        " <li id=\"ge\">Genesis</li>\n",
        " <li id=\"ex\">Exodus</li>\n",
        " <li id=\"le\">Leviticus</li>\n",
        " <li id=\"nu\">Numbers</li>\n",
        " <li id=\"de\">Deuteronomy</li>\n",
        "</ul>\n",
        "#이렇게 ul 리스트가 있으면\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "fp = open(\"books.html\", encoding=\"utf-8\")\n",
        "soup = BeautifulSoup(fp, \"html.parser\")\n",
        "# CSS 선택자로 검색하는 방법\n",
        "sel = lambda q : print(soup.select_one(q).string)   \n",
        "sel(\"#nu\")\n",
        "sel(\"li#nu\")\n",
        "sel(\"ul > li#nu\")\n",
        "sel(\"#bible #nu\")\n",
        "sel(\"#bible > #nu\")\n",
        "sel(\"ul#bible > li#nu\")\n",
        "sel(\"li[id='nu']\")\n",
        "sel(\"li:nth-of-type(4)\")\n",
        "# 그 밖의 방법\n",
        "print(soup.select(\"li\")[3].string)\n",
        "print(soup.find_all(\"li\")[3].string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX_ppW1NISt8"
      },
      "source": [
        "sel(\"#nu\")    \n",
        "sel(\"li#nu\")    \n",
        "sel(\"ul > li#nu\")    \n",
        "sel(\"#bible #nu\")    \n",
        "sel(\"#bible > #nu\")    \n",
        "sel(\"ul#bible > li#nu\")   \n",
        "sel(\"li[id='nu']\")   \n",
        "sel(\"li:nth-of-type(4)\")    \n",
        "이 방법들 중에 무엇을 써도 상관없다는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5t6ZhhwItZU"
      },
      "source": [
        "§ CSS 선택자로 추출 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfQnl1TjIves",
        "outputId": "770d0595-8e85-4952-96cf-d0e854eb1735"
      },
      "source": [
        "\"\"\"\n",
        "<html>\n",
        "<body>\n",
        "<div id=\"main-goods\" role=\"page\">\n",
        " <h1>과일과 야채</h1>\n",
        " <ul id=\"fr-list\">\n",
        "  <li class=\"red green\" data-lo=\"ko\">사과</li>\n",
        "  <li class=\"purple\" data-lo=\"us\">포도</li>\n",
        "  <li class=\"yellow\" data-lo=\"us\">레몬</li>\n",
        "  <li class=\"yellow\" data-lo=\"ko\">오렌지</li>\n",
        " </ul>\n",
        " <ul id=\"ve-list\">\n",
        "  <li class=\"white green\" data-lo=\"ko\">무</li>\n",
        "  <li class=\"red green\" data-lo=\"us\">파프리카</li>\n",
        "  <li class=\"black\" data-lo=\"ko\">가지</li>\n",
        "  <li class=\"black\" data-lo=\"us\">아보카도</li>\n",
        "  <li class=\"white\" data-lo=\"cn\">연근</li>\n",
        " </ul>\n",
        "</div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "fp = open(\"fruits-vegetables.html\", encoding=\"utf-8\")\n",
        "soup = BeautifulSoup(fp, \"html.parser\")\n",
        "\n",
        "# CSS 선택자로 추출하기\n",
        "print(soup.select_one(\"li:nth-of-type(4)\").string)   #모든 li태그 중 순서가 4번째인 오렌지\n",
        "print(soup.select_one(\"#ve-list > li:nth-of-type(4)\").string)  #ve-list 중 li태그 4번째인 아보카도\n",
        "\n",
        "print(soup.select(\"#ve-list > li[data-lo='us']\")[1].string)   #us에서 2번째 자리에 있는 아보카도\n",
        "\n",
        "print(soup.select(\"#ve-list > li.black\")[1].string)   #balck 중 두번째인 아보카도\n",
        "# find 메서드로 추출하기\n",
        "cond = {\"data-lo\":\"us\", \"class\":\"black\"}   \n",
        "print(soup.find(\"li\", cond).string)    #us에서 black에 있는 첫번째 아보카도 (find는 첫 번째 걸 출력)\n",
        "# find 메서드를 연속적으로 사용하기\n",
        "print(soup.find(id=\"ve-list\").find(\"li\", cond).string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "오렌지\n",
            "아보카도\n",
            "아보카도\n",
            "아보카도\n",
            "아보카도\n",
            "아보카도\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoIAp24KMrco"
      },
      "source": [
        "§ 정규 표현식 조합하여 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ9saAXbMsWe",
        "outputId": "70424277-c9c2-4384-9a7a-54030d2817e6"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re # 정규 표현식을 사용할 때\n",
        "\n",
        "html = \"\"\"\n",
        "<ul>\n",
        " <li><a href=\"hoge.html\">hoge</li>\n",
        " <li><a href=\"https://example.com/fuga\">fuga*</li>\n",
        " <li><a href=\"https://example.com/foo\">foo*</li>\n",
        " <li><a href=\"http://example.com/aaa\">aaa</li>\n",
        "</ul>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "# 정규 표현식으로 href에서 https인 것 추출하기\n",
        "li = soup.find_all(href=re.compile(r\"^https://\"))   #https:// 로 시작하는 걸 찾아야 한다\n",
        "for e in li:\n",
        "  print(e.attrs['href'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://example.com/fuga\n",
            "https://example.com/foo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBkvbo2baAz0",
        "outputId": "fabc12e5-247c-4029-8777-8e380570ac44"
      },
      "source": [
        "#모듈 연습문제 네이버 영화 평점\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "movie_title=[]\n",
        "movie_point=[]\n",
        "movie_review=[]\n",
        "for n in range(1, 11):    #range(1, 11)은 페이지를 말하는 것 1페이지~10페이지를 뜻함\n",
        "  req = requests.get('https://movie.naver.com/movie/point/af/list.nhn?page='+str(n)) #n은 페이지숫자\n",
        "  html =req.text\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  titles = soup.select(\".movie\")\n",
        "  points = soup.select('td.title > div > em')\n",
        "  reviews = soup.select('td.title')\n",
        "  for dom in titles:\n",
        "    movie_title.append(dom.text)\n",
        "  for dom in points:\n",
        "    movie_point.append(dom.text)\n",
        "  for dom in reviews:\n",
        "    content = dom.contents[6]\n",
        "    content = re.sub('[\\n\\t]', \"\", content)\n",
        "    content = re.sub('신고', \"\", content)\n",
        "    movie_review.append(content)\n",
        "\n",
        "for i in range(len(movie_title)) :\n",
        "  print('영화제목:', movie_title[i])\n",
        "  print('평점:', movie_point[i])\n",
        "  print('리뷰:', movie_review[i])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 최고! 고질라 시리지 고증 최고 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: \n",
            "영화제목: 인천스텔라\n",
            "평점: 10\n",
            "리뷰: 무슨 약을 해야 이런 신박한 영화를 만드는거죠?ㅋㅋㅋㅋ \n",
            "영화제목: 닥터 두리틀\n",
            "평점: 10\n",
            "리뷰: 그냥 아기 다들 로다주 볼려고 온듯ㅋㅋㅋㅋ \n",
            "영화제목: 인천스텔라\n",
            "평점: 10\n",
            "리뷰: 우주로맨스활극답게 유쾌하다! \n",
            "영화제목: 최면\n",
            "평점: 10\n",
            "리뷰: 생각보다 재미있게 봤습니다~ \n",
            "영화제목: 최면\n",
            "평점: 10\n",
            "리뷰: 2021년 첫공포 괜찮은 출발이네~ \n",
            "영화제목: 아저씨\n",
            "평점: 10\n",
            "리뷰: 아이..잔인함..안봐도 알것같아서..맘무거워.. 여태 미루다 이제 봤는데 역시나 최고네요 색감 눈빛 분위기 최고의 느와르! \n",
            "영화제목: 잔칫날\n",
            "평점: 2\n",
            "리뷰: 경만이 처럼 답답하고 한심하고 멍청한사람이 또 있을까.보는 내내 고구마먹는 느낌이네요. \n",
            "영화제목: 더 박스\n",
            "평점: 10\n",
            "리뷰: \n",
            "영화제목: 어쌔신\n",
            "평점: 10\n",
            "리뷰: 굿. 1990년도 중반에 만들어진 영화맞음? \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 걍 히어로물과는 다른 재미 이번에 대결씬 멋짐 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 1\n",
            "리뷰: SF 짬뽕 킹콩판 서유기도 아니고...아이맥스로 보다가 중간에 나왔어요~ㅠ \n",
            "영화제목: 말레나\n",
            "평점: 10\n",
            "리뷰: 이 영화를 알기 전과 본 후로 인생이 달라졌다. 아름다우면서, 동시에 세상을 강직하고 선하게 살아가려는 여자분들은 꼭 봐야할 영화. \n",
            "영화제목: 잭 스나이더의 저스티스 리그\n",
            "평점: 7\n",
            "리뷰: 딱 포토 1 까지만 좋았던 ' 아름다운 ' 영화 .. \n",
            "영화제목: 천군\n",
            "평점: 1\n",
            "리뷰: \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 그냥 재미있음 더 할말이 없다.. \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 도끼로 썰어버리는거 통쾌함 ㅋㅋㅋ \n",
            "영화제목: 뮬란\n",
            "평점: 1\n",
            "리뷰: 원작을 망쳐도 이렇게 망치냐 ㅉㅉㅉ.ㅉㅉㅉㅉ \n",
            "영화제목: 써니\n",
            "평점: 1\n",
            "리뷰:  홍어들만 고통스러웠던 전두환 대통령을 3번 째로 존경해 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 가볍게 즐기시는 용으로는 좋은거같아요!! \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 8\n",
            "리뷰: 콩.고질라 다 좋아하는데.이번 영화는 그냥 콩 밀어주기네요.좀 노골적으로.일부러 콩 에 유리한 설정 많이 갖다 붙이고.고질라는 그냥 비중있는 단역 정도.조연도 안되요.메카고질라 설정은 진짜 개똥인게 , 지구인간 따위가 어떻게 할로우어스 에너지를 받을 기계를 만드나요.그리고 어떻게 복제를 하고.제일 안타깝습니다.그 부분이.무슨 외계  기술이라도 있었다면 모를까.그런 부분들 말고는 괜찮았습니다.괴수 비중도 늘었고.그래픽도 훌륭합니다.차기작 꼭 나왔으면 하고.그땐 고질라 다시 대접 받으면 좋겠습니다. \n",
            "영화제목: 아수라도\n",
            "평점: 10\n",
            "리뷰: 저예산 독립영화 라고 하기에 너무 잼나는것 같아요스릴과 액션으로 이루어져  너무 좋았어요연기하시는 배우분들도  다 잘하시고괞찬은 영화예요 좋아요  굿굿 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 8\n",
            "리뷰: 액션은 정말 좋았고 분량도 꽤 있엇던 거같다. 하지만 너무뻔한 스토리였다는게 단점이다. 그래도 인간비중이 많진 않아서 볼만했다. \n",
            "영화제목: 소울\n",
            "평점: 10\n",
            "리뷰: \n",
            "영화제목: 동사서독 리덕스\n",
            "평점: 10\n",
            "리뷰: 좋다. 왕가위의 영화를 이해하기 위해선 나이를 먹어야 하나보다. \n",
            "영화제목: 반지의 제왕: 왕의 귀환\n",
            "평점: 10\n",
            "리뷰: 드디어 반지의 제왕 다 본 눈이 되었습니다... 되자마자 다시 안 본 눈으로 돌아가고 싶다, 마치 처음 이 영화를 봤을 때의 감흥을 몇 번이고 느끼고 싶어서요... \n",
            "영화제목: 극장판 귀멸의 칼날: 무한열차편\n",
            "평점: 10\n",
            "리뷰: 최고 멋져 사랑해 렌곸흙휴 \n",
            "영화제목: 버드맨\n",
            "평점: 10\n",
            "리뷰: 사랑 받기 위해 인정받고 싶은데 남들이 사랑 없는 인정을 할 때 \n",
            "영화제목: 아수라도\n",
            "평점: 10\n",
            "리뷰: 잼있게  잘 봤습니다.... \n",
            "영화제목: 뉴욕 라이브러리에서\n",
            "평점: 2\n",
            "리뷰: 206분? 왜? 206시간 짜리로 해지? ;;; \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 이게... 이게 괴수영화다... 전작 카메라는 나가서 그랜절 하고 있어 죽기싫으면 어>????ㅇ?ㅇ?? \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 안녕하세요 저는 영화를 막 시청한 관람객입니다 이영화를 봤는데 너무 재밌었어요 인상깁었던 장면은 배위에서 킹콩이 고질라에게 주먹을 날리던 장면이 인상깁었어요 고질라vs콩 화이팅!! \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 몬스터버스 끝나서 아쉽다. 계속됐으면 함 \n",
            "영화제목: 반도\n",
            "평점: 1\n",
            "리뷰: 감독새끼가 갈수록 영화 못만드네? \n",
            "영화제목: 최면\n",
            "평점: 10\n",
            "리뷰: 최근 본 공포영화 중에 최고였네요.  여곡성, 0.0Mhz, 데자뷰,고死: 피의 중간고사 등에 휠씬 대박인 작품입니다. 이런 작품을 다시 볼 수 있다는게 너무 감사합니다.  블루레이로 소장 가치가 뛰어납니다. \n",
            "영화제목: 마빈의 방\n",
            "평점: 8\n",
            "리뷰: 키튼 언니 너무 예뻐요~~~;;; \n",
            "영화제목: 반지의 제왕: 두 개의 탑\n",
            "평점: 10\n",
            "리뷰: 이 걸작을 왜 이제야 봤을까... 아니 이제라도 봐서 다행이다, 라고 해야겠다. \n",
            "영화제목: 정말 먼 곳\n",
            "평점: 8\n",
            "리뷰: \n",
            "영화제목: 미나리\n",
            "평점: 10\n",
            "리뷰: 최고입니다. 말이필요없네요. \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 8\n",
            "리뷰: 재밌게 잘 봤습니다킹콩 고질라 \n",
            "영화제목: 국도극장: 감독판\n",
            "평점: 8\n",
            "리뷰: 연출, 각본, 앵글, 연기 귿~~~! \n",
            "영화제목: 극장판 귀멸의 칼날: 무한열차편\n",
            "평점: 10\n",
            "리뷰: 흑ㅠㅠㅠㅠ이렇게재밌어도되는거냐고두번보세요 세번보세요 ㄹㅇ \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 9\n",
            "리뷰: 역대 고질라 시리즈 중 가장 볼거리가 많네요. 일단 가장 많이 부수네요. \n",
            "영화제목: 카모메 식당\n",
            "평점: 1\n",
            "리뷰: 너무 지루해서 영화를 여러번 나눠서 봤습니다. 평점이 높아서 기대하고 봤는데 배우분들이 다 연기를 너무 못해요...  진짜 내가 다 어색해서 못 보겠음. 그래서 나갔다 마음먹고 다시 이어서 본 게 여러번입니다. 다른 사람들은 재밌었을지 몰라도 추천받아서 봤는데 저는 별로였어요. \n",
            "영화제목: 더 박스\n",
            "평점: 10\n",
            "리뷰: 힐링되는 영화인 것 같네요 \n",
            "영화제목: 검객\n",
            "평점: 1\n",
            "리뷰: 개취겠지만 이건 평점 조작까지 의심된다. \n",
            "영화제목: 와일드 마운틴 타임\n",
            "평점: 10\n",
            "리뷰: 갑자기 주어진 자유시간에 보게된 혼영.생각지도않게 여운이 오랫동안 남아 미소짓게하네요.감사합니다.이런 영화 넘 힐링되네요 \n",
            "영화제목: 파파로티\n",
            "평점: 7\n",
            "리뷰: 13.05.18.한석규느님은 언제나 좋아요. 흑심 100%. \n",
            "영화제목: 연평해전\n",
            "평점: 10\n",
            "리뷰: 북괴놈들 너무나도 슬픕니다. 호국영령들에게 감사한 마음을 가집니다. \n",
            "영화제목: 이레이저 헤드\n",
            "평점: 7\n",
            "리뷰: 감독이 어떻게 하면 사람 기분 드럽게 할지 연구를 많이 한 것 같다 특히 사운드.... 영화 러닝타임 내내 옆에서 스티로폼 긁어대는 느낌이었다. \n",
            "영화제목: 아이언맨 3\n",
            "평점: 7\n",
            "리뷰: 13.05.19.2편이 처참해서 그랬나 감동 그 자체였다. \n",
            "영화제목: 아수라도\n",
            "평점: 10\n",
            "리뷰: 재밌게 잘봤습니다. 연기가 굿굿입니다^^ \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 8\n",
            "리뷰: 영상미는 좋지만 인위적임 감정표현이 유치함 \n",
            "영화제목: 더 박스\n",
            "평점: 1\n",
            "리뷰: 주연:찬열에서 믿고 거른다. \n",
            "영화제목: 주먹왕 랄프\n",
            "평점: 9\n",
            "리뷰: 13.05.14.모든 게이머들은 고전 게임에게 감사와 존중을. \n",
            "영화제목: 택시운전사\n",
            "평점: 10\n",
            "리뷰: 하 이거 진짜 몇번을 봐도 눈물쏟는다... 실화라는게 믿겨지지 않을 정도 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 8\n",
            "리뷰: 볼거리 하나는 확실한 영화입니다. \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 쉽게 말해줍니다.  한국영화만 보던 친구도 외국영화 항상별로 볼거없다했는데 이거는 보고나서 재미있었다고 말합니다. 여운이 생각보다 많이 남았다고 하네요 \n",
            "영화제목: 잭 스나이더의 저스티스 리그\n",
            "평점: 10\n",
            "리뷰: 이게 영화다 술한잔하고 남긴다 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 고질라, 콩 둘다 팔 다리가 멀쩡한게 이상할 정도로 죽도록 싸움!! 잼있게 봤네요 \n",
            "영화제목: 위플래쉬\n",
            "평점: 10\n",
            "리뷰: 마지막 장면에서 앤드류의 열정보다는 자기 학대의 면모가 더 느껴졌다 열정에 관한 영화가 아닌 오히려 과도한 열정을 비판하는 영화 같다 노력,열정 등의 이름으로 자신을 스스로 착취하고 병들게 하는 게 과연 바람직한 삶일까... \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 4\n",
            "리뷰: 그래픽은 좋으나 보는내내 예상이 가는 클리셰 덩어리 집합체 \n",
            "영화제목: 더 박스\n",
            "평점: 10\n",
            "리뷰: This is an incredibly amazing movie to watch!! The plot, settings, the music is all good and perfect, Chanyeol and Jo Dal Hwan's chemistry is undeniably amazing, on fire , and is on another level. The Character of Jihoon fits Chanyeol perfectly. This movie teaches us how to face our anxiety well, and the  journey of life well, Bravo to all!!! \n",
            "영화제목: 아수라도\n",
            "평점: 3\n",
            "리뷰: 건달 말투나 표정이 어색하구만 댓글에 연기극찬은 뭐꼬 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 8\n",
            "리뷰: 영상미가 좋다. 빌런이 더 멋있다. 스토리는 개판. \n",
            "영화제목: 작전\n",
            "평점: 10\n",
            "리뷰: 최고입니다매년마다 다시보고 있네요 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 8\n",
            "리뷰: 이보다 웅장하고 재밌는 싸움 구경이 있을랑가ㅎㅎㅎ 스토리는 마 됐고ㅋㅋㅋ 웅장한 CG와 액션으로 가득해서 충분히 만족 ㅎㅎㅎ \n",
            "영화제목: 잭 스나이더의 저스티스 리그\n",
            "평점: 10\n",
            "리뷰: \n",
            "영화제목: 노무현입니다\n",
            "평점: 10\n",
            "리뷰: 죄송하고 너무 그립습니다.... \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 전작에서 인간 비중 많다고 욕먹더니 피드백 반영했나보네 이거지 괴수물 시원시원하게 잘 만들었다. 할건 다 한 영화 액션도 휼륭함 \n",
            "영화제목: 소울\n",
            "평점: 10\n",
            "리뷰: 인생이, 삶의 의미가, 존재의 이유가 궁금하다면 꼭 한번 보라고 권하고 싶은 영화. 고딩 큰아이랑 보면서 폭풍 오열하고 나옴. 내돈 내고 2주 안에 두번 본 유일한 영화. \n",
            "영화제목: 인싸\n",
            "평점: 6\n",
            "리뷰: 배우마저도 못봐주겠다고 안본 영화 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 9\n",
            "리뷰: 장엄한 광경.. 완벽한 극장용 무비 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 솔직히 예고편이 다겠지 했는데 와우...너무 웅장하고  보는 내내 입이 쫙쫙벌어지는..암튼 진짜 최고.. \n",
            "영화제목: 클래식\n",
            "평점: 10\n",
            "리뷰: 울고 싶다면 무조건 봐요 \n",
            "영화제목: 모털 엔진\n",
            "평점: 4\n",
            "리뷰: 일단 중국 내 타 민족들을 탄압하고 억누르는 짱깨들 입에서 생명 존중 드립 나왔을 때 ㄹㅇ 개웃겼습니다. 그래서 평점 4점 드려요 ㅎㅎ 오랜만에 웃었네요 \n",
            "영화제목: 마리오네트\n",
            "평점: 10\n",
            "리뷰: 재밌는데 클레멘타인은 넘지 못함 \n",
            "영화제목: 극장판 귀멸의 칼날: 무한열차편\n",
            "평점: 10\n",
            "리뷰: \n",
            "영화제목: 미나리\n",
            "평점: 9\n",
            "리뷰: 한예리의 연기에 놀랐다. 윤여정, 스티븐 연 만 언급이 되곤 하는데 한예리의 농익은 연기에 놀라고 왔다. 결말부분에서 잠깐 울었는데 왜 울었냐고 물으면 잘 모르겠다. 굳이 대답을 찾으라면 삶 때문에. 어떻게든 살아야 하는 삶 때문에.. 대단한 내러티브도 없는데 이토록 명징하게 척박한 삶을 그려낼 수 있다니. \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 서사는 아쉽지만 정말 재밌게 봤습니다 \n",
            "영화제목: 와일드 마운틴 타임\n",
            "평점: 8\n",
            "리뷰: 속터지는 커플이야기 영상미 예쁘고 볼만해요 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 확실하게 부셔준다! \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 좀 루즈한 감이 있지만 재밌습니나 \n",
            "영화제목: 반지의 제왕: 왕의 귀환\n",
            "평점: 10\n",
            "리뷰: 최고예요. 또 보고싶어요 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 기다렸던 고질라 대 콩 영화 봤는데 너무 재밌어요 저의 최애 영화가 될겄같네욯ㅎ \n",
            "영화제목: 극장판 귀멸의 칼날: 무한열차편\n",
            "평점: 10\n",
            "리뷰: 다행이다 4DX로 봤으면 진심으로 지릴 뻔 했다 \n",
            "영화제목: 쇼생크 탈출\n",
            "평점: 10\n",
            "리뷰: \n",
            "영화제목: 마리오네트\n",
            "평점: 10\n",
            "리뷰: 무척 훌륭한 영화입니다!!! 이거 추천해주시는 분들은 정말 태어나서 영화란걸 처음 본 영잘알들이 분명합니다!!! 안목이 탁월하시네요!!! 나만 당할 순 없다!!! 어서 빨리 이 영화 보시고 12000원을 기부하세요!!! \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 8\n",
            "리뷰: 이영화의 승자는 역시 고질라였습니다. 그것도 압도적으로 콩을 발라버린 느낌.. 그리고 찐 주인공은 메카고질라였습니다... 정말 기존에 알던 메카고질라가 맞는지 싶을정도로 고질라와 콩을 상대로 가지고놀던데 최고였습니다. \n",
            "영화제목: 밀양\n",
            "평점: 8\n",
            "리뷰: 좀 지루한감은 있으나 볼만했어요 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 지아가 콩한테 집이 저기 있다고 하는데 나까지 울컥하더라 ㅠㅠ 콩 갬성무슨일이야ㅠㅠㅠ \n",
            "영화제목: 검은 사제들\n",
            "평점: 10\n",
            "리뷰: 박소담 악령그자체인줄... 신들린연기가 아니라 악령들린연기....미쳤다 \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 9\n",
            "리뷰: 고질라와 콩의 싸움에서 한번도 볼 수 없었던 중압감을 느낌. \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 괴수둘로 전투씬을 이정도로 시원하게 뽑아내다니무조건 큰화면으로  영화관에서  보시길 N차관람 예정 \n",
            "영화제목: 미나리\n",
            "평점: 5\n",
            "리뷰: 어.... 음.... 결말이 진짜.. 나는 영화 실컷 잘 보고 있는데 누가 갑자기 영화 중간에 엔딩 크레딧 틀어버린 느낌..;;; \n",
            "영화제목: 잭 스나이더의 저스티스 리그\n",
            "평점: 10\n",
            "리뷰: 최고★★★★♥♥♥♥ \n",
            "영화제목: 고질라 VS. 콩\n",
            "평점: 10\n",
            "리뷰: 최고다  걍   액션으로  대만족 \n",
            "영화제목: 천군\n",
            "평점: 1\n",
            "리뷰: ㅈ장ㄱㅐ색ㅎI 영화 컷ㅋㅋ \n",
            "영화제목: 더 박스\n",
            "평점: 10\n",
            "리뷰: 언니랑 빨리 다시 보고 싶어! 영화가 너무 좋아!! \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQcy1rIQbi6p",
        "outputId": "f26b858a-3bbc-4473-d286-e38c41825ad9"
      },
      "source": [
        "#연습문제\n",
        "# 교보문고 베스트셀러 책이름, 저자, 가격 Crawling\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "# 교보문고 베스트셀러\n",
        "html = urlopen(\"http://www.kyobobook.co.kr/bestSellerNew/bestseller.laf\") \n",
        "soup = bs(html, \"html.parser\") \n",
        "\n",
        "title = soup.select_one(\"div.title > a > strong\")\n",
        "print('제목', title.string)\n",
        "writers = soup.select_one('div.detail > div.author > span.popup_load.uxOpenList > ul > li')\n",
        "for w in writers:\n",
        "  print('저자:', w.string)\n",
        "prices = soup.select_one('strong.book_price')\n",
        "for p in prices:\n",
        "  print('가격', p.string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "제목 흔한남매. 7(양장본 HardCover)\n",
            "저자: 백난도\n",
            "가격 10,800원\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}