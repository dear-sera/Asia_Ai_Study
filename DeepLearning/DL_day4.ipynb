{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_day4.ipynb",
      "provenance": [],
      "mount_file_id": "1bLZ3JMenaAKRwO3_9XKk-4Xg8peYeSc1",
      "authorship_tag": "ABX9TyMx4TQRxCdguuT/bC1p1QVg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sera0911/asia_ai_study/blob/main/DeepLearning/DL_day4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR4_AQaCGg1o"
      },
      "source": [
        "\n",
        "텍스트 분석 - 분류, 감정분석, 요약(토픽 모델링), 군집화  \n",
        "\n",
        "텍스트 분석을 위한 전처리 과정 :  \n",
        "1. cleaning - 불필요한 문자, 기호 제거\n",
        "2. tokenization - 문장 토큰화, 단어 토큰화, 단어 순서 고려한 토큰화\n",
        "3. 필터, 절차 수정, stop word 제거\n",
        "4. 어근 추출 (의미를 갖는 단어 원형 추출 ) - Steamming, Lemmatiziton  \n",
        "5. 정규화 - 추출된 단어 기반으로 수치 벡터화, Count, tf-idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sPbcYfQNDRy"
      },
      "source": [
        "### 감성 분석\n",
        "\n",
        "• 문서의 주관적인 감성/의견/감정/기분 등을 파악하기 위한 방법\n",
        "\n",
        "• 문서 내 텍스트가 나타내는 여러 가지 주관적인 단어와 문맥을 기반으로 감성 수치를 계산하는 방법을 이용\n",
        "\n",
        "• 지도학습 – 학습 데이터와 타깃 레이블 값을 기반으로 감정 분석을 수행한 뒤 이를 기반으로 다른 데이터의 감정 분석을 예측하는 방법\n",
        "\n",
        "• 비지도 학습 - Lexicon이라는 일종의 감정 어휘 사전을 이용\n",
        "\n",
        "• Lexicon - 감정 분석을 위한 용어와 문맥에 대한 다양한 정보를 가지고 있으며, 이를 이용해 문서의 긍정적, 부정적 감성 여부를 판단합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqVU0hCeNxpO"
      },
      "source": [
        "감성 분석 순서\n",
        "\n",
        "1. 클린징\n",
        "2. 학습, 테스트 데이터 분리\n",
        "3. 피처 벡터화 (CountVectorizer)\n",
        "4. ML분류 알고리즘 LogisticRegression 적용\n",
        "5. 예측 성능 평가 - 정확도와 ROC-AUC를 측정\n",
        "6. TF-IDF벡터화\n",
        "7. ML분류 알고리즘 LogisticRegression 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0HzDgVWGZr5",
        "outputId": "9a7195de-7c03-48cc-bc2e-deca8c19b737"
      },
      "source": [
        "# 지도학습 기반 IMDB 영화평 감정 분석\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "review_df = pd.read_csv('labeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
        "review_df.head()\n",
        "\n",
        "print(review_df['review'][0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcAkseNqQMYI"
      },
      "source": [
        "import re\n",
        "\n",
        "#<br> html 태그는 replace 함수로 공백으로 변환\n",
        "review_df['review'] = review_df['review'].str.replace('<br />',' ')\n",
        "\n",
        "#re 모듈을 이용하여 영어 문자열이 아닌 문자는 모두 공백으로 변환\n",
        "review_df['review'] = review_df['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
        "\n",
        "#변환이 잘 됐는지 확인\n",
        "#print(review_df['review'][0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVvpZednRCJP",
        "outputId": "9bd6ed87-d94e-47a8-8a87-2fede5dfa738"
      },
      "source": [
        "#학습, 테스트 데이터 분할\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class_df = review_df['sentiment']\n",
        "feature_df = review_df.drop(['id', 'sentiment'], axis = 1, inplace=False)\n",
        "print(feature_df)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, class_df, test_size = 0.3, random_state = 156)\n",
        "\n",
        "X_train.shape, X_test.shape  #((17500, 1), (7500, 1))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  review\n",
            "0       With all this stuff going down at the moment ...\n",
            "1         The Classic War of the Worlds   by Timothy ...\n",
            "2       The film starts with a manager  Nicholas Bell...\n",
            "3       It must be assumed that those who praised thi...\n",
            "4       Superbly trashy and wondrously unpretentious ...\n",
            "...                                                  ...\n",
            "24995   It seems like more consideration has gone int...\n",
            "24996   I don t believe they made this film  Complete...\n",
            "24997   Guy is a loser  Can t get girls  needs to bui...\n",
            "24998   This    minute documentary Bu uel made in the...\n",
            "24999   I saw this movie as a child and it broke my h...\n",
            "\n",
            "[25000 rows x 1 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17500, 1), (7500, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYOgJIkER6p0",
        "outputId": "f20d3c21-2e02-4dd0-ad84-4e54c5e6387a"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# 스톱 워드는 English, Filtering, Ngram은 (1, 2)로 설정하여 CountVectorization 수행\n",
        "# LogisticRegression의 C는 10으로 설정\n",
        "pipeline = Pipeline([\n",
        "                     ('cnt_vect', CountVectorizer(stop_words = 'english', ngram_range=(1, 2))), \n",
        "                     ('lr_clf', LogisticRegression(C=10))])\n",
        "\n",
        "# Pipeline 객체를 이용해 fit(), predict()로 학습/예측 수행, predict_proba()는 roc_auc 때문에 수행. \n",
        "pipeline.fit(X_train['review'], y_train)\n",
        "pred = pipeline.predict(X_test['review'])\n",
        "\n",
        "print('CountVectorizer 예측 정확도는 {0:.4f}'.format(accuracy_score(y_test, pred)))\n",
        "\n",
        "#CountVectorizer 예측 정확도는 0.8860"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer 예측 정확도는 0.8860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Co3QBdST75",
        "outputId": "89d83fde-5ea3-4ece-a23a-e96efc056ff0"
      },
      "source": [
        "# 스톱 워드는 english, filtering, ngram은 (1, 2)로 설정해 TF-IDF 벡터화 수행\n",
        "# LogisticRegression의 C는 10으로 설정\n",
        "pipeline = Pipeline([\n",
        "                     ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range = (1, 2))), \n",
        "                     ('lr_clf', LogisticRegression(C=10))])\n",
        "                     \n",
        "pipeline.fit(X_train['review'], y_train)-\n",
        "pred = pipeline.predict(X_test['review'])\n",
        "\n",
        "print('TfidfVectorizer 예측 정확도는 {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfidfVectorizer 예측 정확도는 0.8936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATyCuiAmU-ap"
      },
      "source": [
        "감성 분석\n",
        "\n",
        "• NLTK : 시맨틱을 프로그램적으로 인터페이스화 할 수 있게 제공  \n",
        "• 제공되는 WordNet은 다양한 상황에서 같은 어휘라도 다르게 사용되는 어휘의 시맨틴 정보를 제공\n",
        "\n",
        "• SentiWordNet : NLTK패키지의 WordNet과 유사  \n",
        "• 감성 단어 전용의 WordNet을 구현  \n",
        "• WordNet의 Synset별로 3가지 감성 점수를 할당합니다.  \n",
        "• SentiWordNet 모듈의 senti_synsets()는 WordNet 모듈이라서 synsets()와 비슷하게 Senti_Synset 클래스를 리스트 형태로 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeufNFVOYRZQ"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avowo0kiYi-X",
        "outputId": "3539ee53-0b43-4f04-b381-a65921f6fd96"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "#WordNet (동의어/반의어 사전)\n",
        "term = 'present'\n",
        "synsets = wn.synsets(term)\n",
        "print('synsets() 반환 type:', type(synsets))\n",
        "print('synsets() 반환 값 개수:', len(synsets))\n",
        "print('synsets() 반환 값:', synsets)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "synsets() 반환 type: <class 'list'>\n",
            "synsets() 반환 값 개수: 18\n",
            "synsets() 반환 값: [Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S7ctrBnZmGE"
      },
      "source": [
        "#18개의 객체가 가지는 속성 확인\n",
        "#preset의 여러 의미를 걔층구조 상위어, 하위어 정보를 반환\n",
        "for synset in synsets:\n",
        "  print(\"#### Synset name :\", synset.name(), \"####\")\n",
        "  print(\"POS :\", synset.lexname()) \n",
        "  print('Definition:', synset.definition())\n",
        "  print('Lemmas:', synset.lemma_names())\n",
        "\n",
        "#synset은 비슷한 단어 묶음\n",
        "#pos() : 품사 출력, example(): 예제 문장, hypernym(): 상위어, hyponym(): 하위어\n",
        "#lemmas(): 단어에 대한 기본형 리스트, synset의 동의어\n",
        "#n:명사, v:동사, a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ozp8FyfFZtUM",
        "outputId": "bcacc25b-c00b-4a21-bd60-4ffbba69bf75"
      },
      "source": [
        "#단어를 sysnset객체로 생성\n",
        "\n",
        "tree = wn.synset('tree.n.01')\n",
        "tiger = wn.synset('tiger.n.01')\n",
        "lion = wn.synset('lion.n.01')\n",
        "cat = wn.synset('cat.n.01')\n",
        "dog = wn.synset('dog.n.01')\n",
        "\n",
        "entities = [tree, tiger, lion, cat, dog]\n",
        "similarities = []\n",
        "entity_names = [entity.name().split('.')[0] for entity in entities]\n",
        "\n",
        "# 단어별 synset을 반복하면서 다른 단어의 `synset`과 유사도를 측정함\n",
        "for entity in entities:\n",
        "  similarity = [round(entity.path_similarity(compared_entity), 2) for compared_entity in entities]\n",
        "  similarities.append(similarity)\n",
        "\n",
        "# 개별 단어별 synset과 다른 단어의 `synset`과의 유사도를 `DataFrame` 형태로 저장\n",
        "similarity_df = pd.DataFrame(similarities, columns = entity_names, index = entity_names)\n",
        "similarity_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tree</th>\n",
              "      <th>tiger</th>\n",
              "      <th>lion</th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tree</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tiger</th>\n",
              "      <td>0.14</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lion</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat</th>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       tree  tiger  lion   cat   dog\n",
              "tree   1.00   0.14  0.07  0.08  0.12\n",
              "tiger  0.14   1.00  0.08  0.09  0.17\n",
              "lion   0.07   0.08  1.00  0.25  0.17\n",
              "cat    0.08   0.09  0.25  1.00  0.20\n",
              "dog    0.12   0.17  0.17  0.20  1.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY1ikPO9cnWF",
        "outputId": "3e870b93-5d52-4c87-990a-3ceb308445c1"
      },
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "senti_synsets = list(swn.senti_synsets('slow'))\n",
        "print('senti_synsets() 반환 type:', type(senti_synsets))\n",
        "print('senti_synsets() 반환 값 개수:', len(senti_synsets))\n",
        "print('senti_synsets() 반환 값:', senti_synsets)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "senti_synsets() 반환 type: <class 'list'>\n",
            "senti_synsets() 반환 값 개수: 11\n",
            "senti_synsets() 반환 값: [SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoN6qD1adQm1",
        "outputId": "3c766ea5-8178-4491-a434-0570fecb286b"
      },
      "source": [
        "father = swn.senti_synset('father.n.01')\n",
        "print('father 긍정감성 지수: ', father.pos_score())\n",
        "print('father 부정감성 지수: ', father.neg_score())\n",
        "print('father 객관성 지수: ', father.obj_score())\n",
        "\n",
        "fabulous  = swn.senti_synset('fabulous.a.01')\n",
        "print('fabulous  긍정감성 지수: ', fabulous.pos_score())\n",
        "print('fabulous  부정감성 지수: ', fabulous.neg_score())\n",
        "print('fabulous  객관성 지수: ', fabulous.obj_score())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "father 긍정감성 지수:  0.0\n",
            "father 부정감성 지수:  0.0\n",
            "father 객관성 지수:  1.0\n",
            "fabulous  긍정감성 지수:  0.875\n",
            "fabulous  부정감성 지수:  0.125\n",
            "fabulous  객관성 지수:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWs0ux-xiCw6"
      },
      "source": [
        "def penn_to_wn(tag):\n",
        "  if tag.startswith('J'):\n",
        "    return wn.ADJ\n",
        "  elif tag.startswith('N'):\n",
        "    return wn.NOUN\n",
        "  elif tag.startswith('R'):\n",
        "    return wn.ADV\n",
        "  elif tag.startswith('V'):\n",
        "    return wn.VERB"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9qooUhueMz5"
      },
      "source": [
        "#SentiWordNet 영화 감상평 감성 분석\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "def swn_polarity(text):\n",
        "    # 감성 지수 초기화 \n",
        "    sentiment = 0.0\n",
        "    tokens_count = 0\n",
        "    \n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    raw_sentences = sent_tokenize(text)  #문장토큰화\n",
        "\n",
        "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산 \n",
        "    for raw_sentence in raw_sentences:\n",
        "        # NTLK 기반의 품사 태깅 문장 추출  \n",
        "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))  #단어토큰화\n",
        "        for word , tag in tagged_sentence:\n",
        "            # WordNet 기반 품사 태깅과 어근 추출\n",
        "            wn_tag = penn_to_wn(tag)  #품사태깅\n",
        "            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\n",
        "                continue                   \n",
        "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)  #어근 추출\n",
        "            if not lemma:\n",
        "                continue\n",
        "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성. \n",
        "            synsets = wn.synsets(lemma , pos=wn_tag)\n",
        "            if not synsets:\n",
        "                continue\n",
        "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
        "            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산. \n",
        "            synset = synsets[0]\n",
        "            swn_synset = swn.senti_synset(synset.name())\n",
        "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())           \n",
        "            tokens_count += 1\n",
        "    \n",
        "    if not tokens_count:\n",
        "        return 0\n",
        "    \n",
        "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
        "    if sentiment >= 0 :\n",
        "        return 1\n",
        "    \n",
        "    return 0"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3475CsJgDmg"
      },
      "source": [
        "review_df['preds'] = review_df['review'].apply(lambda x: swn_polarity(x))\n",
        "y_target = review_df['sentiment'].values\n",
        "preds = review_df['preds'].values"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhV3c3HNgROh",
        "outputId": "e66dfa54-ae77-4228-ceff-c1dc587972f0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "print(confusion_matrix(y_target, preds))\n",
        "print(\"정확도:\", np.round(accuracy_score(y_target, preds), 4))\n",
        "print(\"정밀도:\", np.round(precision_score(y_target, preds), 4))\n",
        "print(\"재현율:\", np.round(recall_score(y_target, preds), 4))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7668 4832]\n",
            " [3636 8864]]\n",
            "정확도: 0.6613\n",
            "정밀도: 0.6472\n",
            "재현율: 0.7091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98xwgKOMeCjB"
      },
      "source": [
        "#### VADER : 소설 미디어의 텍스트에 대한 감성 분석을 제공하기 위한 패키지\n",
        "\n",
        "• 뛰어난 감성 분석 결과를 제공\n",
        "\n",
        "• 비교적 빠른 수행 시간을 보장해 대용량 텍스트 데이터에 잘 사용되는 패키지\n",
        "\n",
        "• Pattern : 예측 성능 측면에서 가장 주목 받는 패키지"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SevKP0Bmk13d",
        "outputId": "2908005f-7b56-44b0-8e6a-f7c76e356431"
      },
      "source": [
        "#VADER lexion 비지도학습 기반 IMDB 영화평 감정 분석\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "senti_analyzer = SentimentIntensityAnalyzer()\n",
        "senti_scores = senti_analyzer.polarity_scores(review_df['review'][0])\n",
        "print(senti_scores)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'neg': 0.13, 'neu': 0.743, 'pos': 0.127, 'compound': -0.7943}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDBovQz7lwlF"
      },
      "source": [
        "def get_sentiment(review, threshold=0.1):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    scores = analyzer.polarity_scores(review)\n",
        "    compound_score = scores['compound']\n",
        "    #hreshold 입력값보다 크면 1, 그렇지 않으면 0을 반환\n",
        "    final_sentiment = 1 if compound_score >= threshold else 0\n",
        "    return final_sentiment\n",
        "\n",
        " # 각 텍스트 데이터에 위에서 설정한 감성 label 얻는 함수 적용하기\n",
        "# 임계값은 0.1로 설정\n",
        "review_df['vader_pred'] = review_df['review'].apply(lambda x : get_sentiment(x, 0.1))\n",
        "# 원본 데이터에서 주어진 정답 label과 VADER로 예측한 label 비교\n",
        "y_target = review_df['sentiment'].values\n",
        "y_pred = review_df['vader_pred'].values"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6YyDGyOlydG",
        "outputId": "cd549820-2ab9-4e2b-fd3b-75d888cc2bc1"
      },
      "source": [
        "print(confusion_matrix(y_target, y_pred))\n",
        "print(\"정확도 :\", accuracy_score(y_target, y_pred))\n",
        "print(\"정밀도 :\", precision_score(y_target, y_pred))\n",
        "print(\"재현율 :\", recall_score(y_target, y_pred))\n",
        "print(\"F1 score :\", f1_score(y_target, y_pred))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6736  5764]\n",
            " [ 1867 10633]]\n",
            "정확도 : 0.69476\n",
            "정밀도 : 0.6484722815149113\n",
            "재현율 : 0.85064\n",
            "F1 score : 0.7359241443748487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIMCc_DBnrrU"
      },
      "source": [
        "#### 문서 유사도\n",
        "\n",
        "• 자연어 처리에서는 문서의 유사도를 구하여 각 문서간의 주제 유사도를 판별하기도 한다\n",
        "\n",
        "##### • 코사인 유사도(Cosine Similarity)\n",
        "\n",
        "• 코사인 유사도는 두 벡터 간의 각도에 기반하여 구할 수 있는 값이다. 두 벡터의 각도, 즉 방향이 완전히 일치하다면 1을 반환하게 되며, 수직일 경우 0, 완전 정반대 일경우 -1를 반환하게 된다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfY3Utf9nzEf",
        "outputId": "b23afa2a-d739-4ff4-b23c-86c3498c2bf5"
      },
      "source": [
        "#코사인 유사도(Cosine Similarity)\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "import numpy as np\n",
        "\n",
        "def cos_sim(A, B):\n",
        "    return dot(A, B)/(norm(A)*norm(B))\n",
        "\n",
        "vec1=np.array([0,1,1,1]) #문서1 : 저는 사과 좋아요\n",
        "vec2=np.array([1,0,1,1]) #문서2 : 저는 바나나 좋아요\n",
        "vec3=np.array([2,0,2,2]) #문서3 : 저는 바나나 좋아요 저는 바나나 좋아요\n",
        "\n",
        "print(cos_sim(vec1, vec2)) #문서1과 문서2의 코사인 유사도\n",
        "print(cos_sim(vec1, vec3)) #문서1과 문서3의 코사인 유사도\n",
        "print(cos_sim(vec2, vec3)) #문서2과 문서3의 코사인 유사도"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6666666666666667\n",
            "0.6666666666666667\n",
            "1.0000000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQj_8cM9p4JA"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnfTX1AkpC8y"
      },
      "source": [
        "##### 유클리드 거리(Euclidean distance) - 다차원 공간에서의 점과 점 사이의 거리를 구하는 공식\n",
        "\n",
        "• 공식 자체는 피타고라스 정리에서 삼각형의 빗면을 구하는 방식과 똑같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ufgIEILpbqd",
        "outputId": "3f382f02-37ce-4148-e4e2-ebab44c2e3d5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def dist(x,y):\n",
        "    return np.sqrt(np.sum((x-y)**2))\n",
        "\n",
        "vec1 = np.array((2,3,0,1)) #바나나 바나나 사과 사과 사과 좋아요\n",
        "vec2 = np.array((1,2,3,1)) #바나나 사과 사과 저는 저는 저는 좋아요\n",
        "vec3 = np.array((2,1,2,2)) #바나나 바나나 사과 저는 저는 좋아요 좋아요\n",
        "vecQ = np.array((1,1,0,1)) #바나나 사과 좋아요\n",
        "\n",
        "print(dist(vec1,vecQ))\n",
        "print(dist(vec2,vecQ))\n",
        "print(dist(vec3,vecQ))\n",
        "\n",
        "#유클리드 거리의 값이 가장 작다는 것은, 문서 간의 거리가 가장 가깝다는 것"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.23606797749979\n",
            "3.1622776601683795\n",
            "2.449489742783178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV8Nm0-gr7zO"
      },
      "source": [
        "##### 맨허튼 거리 - 유클리드와 마찬가지로 좌표상의 거리를 표현하지만 해당 거리 차이를 절대값의 차이로 계산하는 기법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb27E6Znr-AG",
        "outputId": "56420033-5e4e-4759-d165-33791a9841fb"
      },
      "source": [
        "def dist(x,y):\n",
        "    return np.sum(np.absolute(x-y))\n",
        "\n",
        "vec1 = np.array((2,3,0,1)) #바나나 바나나 사과 사과 사과 좋아요\n",
        "vec2 = np.array((1,2,3,1)) #바나나 사과 사과 저는 저는 저는 좋아요\n",
        "vec3 = np.array((2,1,2,2)) #바나나 바나나 사과 저는 저는 좋아요 좋아요\n",
        "vecQ = np.array((1,1,0,1)) #바나나 사과 좋아요\n",
        "\n",
        "print(dist(vec1,vecQ))\n",
        "print(dist(vec2,vecQ))\n",
        "print(dist(vec3,vecQ))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncNcm4pmq_B0"
      },
      "source": [
        "##### 자카드 유사도(Jaccard similarity) - 각 집합에 대하여 얼마나 같은 원소를 많이 포함하고 있는가를 구하는 기법\n",
        "\n",
        "• 자카드 유사도는 0과 1사이의 값을 가지며, 두 집합이 동일하다면 1의 값을 가지고, 공통 부분이 없다면 0의 값을 가지게 된다.\n",
        "\n",
        "• 집합 연산을 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEr9Mu_TrF5x",
        "outputId": "45dc4ca7-ab17-402b-ee3f-d6f42b6e3cf0"
      },
      "source": [
        "set1 = ['apple', 'banana', 'everyone', 'like', 'likey', 'watch', 'card', 'holder']\n",
        "set2 = ['apple', 'banana', 'coupon', 'passport', 'love', 'you']\n",
        "union = set(set1).union(set(set2)) # 두 집합의 합집합\n",
        "intersection = set(set1).intersection(set(set2)) # 두 집합의 교집합\n",
        "len(intersection)/len(union)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16666666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6DK-O3-srHi"
      },
      "source": [
        "### 토픽 모델링(Topic Modeling)\n",
        "\n",
        "• 기계 학습 및 자연어 처리 분야에서 토픽이라는 문서 집합의 추상적인 주제를 발견하기 위한 통계적 모델\n",
        "\n",
        "• 텍스트 본문의 숨겨진 의미 구조를 발견하기 위해 사용되는 텍스트 마이닝 기법\n",
        "\n",
        "• LSA : DTM을 차원 축소 하여 축소 차원에서 근접 단어들을 토픽으로 묶는다.\n",
        "\n",
        "• LDA : 단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하여 토픽을 추출한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO0ixpPlszmk"
      },
      "source": [
        "• 잠재 의미 분석(Latent Semantic Analysis, LSA)-토픽 모델링이라는 분야에 아이디어를 제공한 알고리즘\n",
        "\n",
        "• DTM(문서 단어 행렬)이나 TF-IDF 행렬에 절단된 SVD(truncated SVD)를 사용하여 차원을 축소시키고, 단어들의 잠재적인 의미를 끌어낸다\n",
        "\n",
        "• Truncated SVD - 절단된 SVD는 대각 행렬 Σ의 대각 원소의 값 중에서 상위값 t개만 남게 됩니다. 절단된 SVD를 수행하면 값의 손실이 일어나므로 기존의 행렬 A를 복구할 수 없습니다. 또한, U행렬과 V행렬의 t열까지만 남깁니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5PkIiCx1Y9v",
        "outputId": "70f1ebb4-f84d-4209-8966-53b68a861d15"
      },
      "source": [
        "#LSA 문서 유사도\n",
        "A = np.array([[0, 0, 0, 1, 0, 1, 1, 0, 0], [0, 0, 0, 1, 1, 0, 1, 0, 0],[0, 1, 1, 0, 2, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
        "np.shape(A)\n",
        "\n",
        "#FullSVD 실행\n",
        "U, s, VT = np.linalg.svd(A, full_matrices= True) #s는 대각행렬\n",
        "\n",
        "print(U.round(2)) # U 직교행렬\n",
        "np.shape(U)\n",
        "\n",
        "print(s.round(2)) # 대각행렬의 특이값의 리스트를 반환\n",
        "np.shape(s)\n",
        "\n",
        "print(VT.round(2)) # V 직교행렬의 역행렬\n",
        "np.shape(VT)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.24  0.75  0.   -0.62]\n",
            " [-0.51  0.44 -0.    0.74]\n",
            " [-0.83 -0.49 -0.   -0.27]\n",
            " [-0.   -0.    1.    0.  ]]\n",
            "[2.69 2.05 1.73 0.77]\n",
            "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
            " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
            " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
            " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
            " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
            " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
            " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
            " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
            " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frEbnfZ_2w7M",
        "outputId": "96828c5c-f49c-4380-cbbd-38b54a5a4107"
      },
      "source": [
        "S = np.zeros((4, 9)) # 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성\n",
        "S[:4, :4] = np.diag(s) # 특이값을 대각행렬에 삽입\n",
        "print(S.round(2))\n",
        "np.shape(S)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLHA8FVH22RS",
        "outputId": "ac9ae3df-54a6-463a-a35b-dbb14a3dc087"
      },
      "source": [
        "# U × S × VT를 하면 기존의 행렬 A가 나와야 합니다. \n",
        "#Numpy의 allclose()는 2개의 행렬이 동일하면 True를 리턴\n",
        "np.allclose(A, np.dot(np.dot(U,S), VT).round(2))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lt_H4WY3Ag9",
        "outputId": "6ef4ea2c-3724-487d-d8a6-322596a939fc"
      },
      "source": [
        "#Truncated SVD 실행 (t=2로 설정)\n",
        "S=S[:2,:2]\n",
        "print(S.round(2))\n",
        "\n",
        "#직교 행렬 U에 대해서도 2개의 열만 남기고 제거\n",
        "U=U[:,:2]\n",
        "print(U.round(2))\n",
        "\n",
        "#행렬 V의 전치 행렬인 VT에 대해서 2개의 행만 남기고 제거\n",
        "VT=VT[:2,:]\n",
        "print(VT.round(2))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.69 0.  ]\n",
            " [0.   2.05]]\n",
            "[[-0.24  0.75]\n",
            " [-0.51  0.44]\n",
            " [-0.83 -0.49]\n",
            " [-0.   -0.  ]]\n",
            "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
            " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilIltxM_3UbB",
        "outputId": "92e44b42-aa69-4633-f023-e6b648a84e56"
      },
      "source": [
        "# U × S × VT를 하면 기존의 행렬 A와 다른 결과가 나옴 (값이 손실되었기 때문=> 기존 행렬 A로 복구 불가)\n",
        "A_prime=np.dot(np.dot(U,S), VT)\n",
        "print(A)\n",
        "print(A_prime.round(2))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 0 1 1 0 0]\n",
            " [0 0 0 1 1 0 1 0 0]\n",
            " [0 1 1 0 2 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 1 1]]\n",
            "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
            " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
            " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.   -0.    0.    0.    0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4r5xHVg1YMq"
      },
      "source": [
        "1. 대체적으로 기존에 0인 값들은 0에 가가운 값이 나오고, 1인 값들은 1에 가까운 값이 나오는 것을 볼 수 있다 \n",
        "2. VT의 각 열은 잠재 의미를 표현하기 위해 수치화된 각각의 단어 벡터라고 볼 수 있다\n",
        "3. Truncated SVD를 이용하여 문서 벡터들과 단어 벡터들을 통해 다른 문서의 유사도, 다른 단어의 유사도, 단어(쿼리)로부터 문서의 유사도를 구하는 것들이 가능\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nql5Esnj4yl1",
        "outputId": "55df2164-4710-49e4-f0b1-a831a8fc9aac"
      },
      "source": [
        "#주제가 다른 20 뉴스그룹 데이터를 토픽 모델링\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data\n",
        "len(documents)\n",
        "\n",
        "documents[1]\n",
        "\n",
        "print(dataset.target_names) #20개의 카테고리 확인\n",
        "\n",
        "news_df = pd.DataFrame({'document':documents})\n",
        "\n",
        "#특수 문자 제거\n",
        "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
        "\n",
        "#길이가 3이하인 단어는 제거\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x:' '.join([w for w in x.split() if len (w)>3]))\n",
        "\n",
        "#전체단어에 대한 소문자 변환\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n",
        "\n",
        "print(news_df['clean_doc'][1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVC6vgB_Mfky",
        "outputId": "2395701b-e239-402b-ba77-29c87737fe1b"
      },
      "source": [
        "# 불용어 처리 및 토큰화\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "tokenized_doc = news_df['clean_doc'].apply(lambda x : x.split())\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "\n",
        "print(tokenized_doc[1])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqfP4GhPM0CF",
        "outputId": "33104b60-1f66-4d6f-bf9b-1ac9645ab5c0"
      },
      "source": [
        "#TF-IDF 행렬 변환 (토큰화가 되어있지 않은 텍스트 데이터를 입력으로 사용)\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000, max_df =0.5, smooth_idf=True)\n",
        "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
        "print(X.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11314, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsaPK2QZNjvW",
        "outputId": "f581ac0e-18b2-495b-c390-045f36b67dac"
      },
      "source": [
        "#토픽 모델링 수행 (Truncated SVD로 차원축소 t=20)\n",
        "#사이킷런의 TruncatedSVD 클래스의 토픽 개수 설정 인수는 n_components\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd_model = TruncatedSVD(n_components=20, algorithm = 'randomized', n_iter=100, random_state=122)\n",
        "svd_model.fit(X)\n",
        "len(svd_model.components_)\n",
        "#학습된 모델의 components_는 LSA의 VT입니다 (tX단어의 수)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k5n7qTLOJdM",
        "outputId": "944f9135-0522-475a-8eda-817eddb8fa6b"
      },
      "source": [
        "#20개의 토픽에서 가장 값이 큰 5개의 단어 출력\n",
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "def get_topics(components, feature_names, n=5):\n",
        "    for idx, topic in enumerate(components):\n",
        "        print('Topic %d: '%(idx + 1), [terms[i] for i in topic.argsort()[: -n - 1: -1]])\n",
        "\n",
        "get_topics(svd_model.components_, terms)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1:  ['just', 'like', 'know', 'people', 'think']\n",
            "Topic 2:  ['thanks', 'windows', 'card', 'drive', 'mail']\n",
            "Topic 3:  ['game', 'team', 'year', 'games', 'drive']\n",
            "Topic 4:  ['drive', 'scsi', 'disk', 'hard', 'problem']\n",
            "Topic 5:  ['drive', 'know', 'thanks', 'does', 'just']\n",
            "Topic 6:  ['just', 'like', 'windows', 'know', 'does']\n",
            "Topic 7:  ['just', 'like', 'mail', 'bike', 'thanks']\n",
            "Topic 8:  ['does', 'know', 'chip', 'like', 'card']\n",
            "Topic 9:  ['like', 'card', 'sale', 'video', 'offer']\n",
            "Topic 10:  ['like', 'drive', 'file', 'files', 'sounds']\n",
            "Topic 11:  ['people', 'like', 'thanks', 'card', 'government']\n",
            "Topic 12:  ['think', 'good', 'thanks', 'need', 'chip']\n",
            "Topic 13:  ['think', 'does', 'just', 'mail', 'like']\n",
            "Topic 14:  ['know', 'good', 'people', 'windows', 'file']\n",
            "Topic 15:  ['space', 'know', 'think', 'nasa', 'card']\n",
            "Topic 16:  ['does', 'israel', 'think', 'right', 'israeli']\n",
            "Topic 17:  ['good', 'space', 'card', 'does', 'thanks']\n",
            "Topic 18:  ['people', 'does', 'window', 'problem', 'space']\n",
            "Topic 19:  ['right', 'bike', 'time', 'windows', 'space']\n",
            "Topic 20:  ['file', 'problem', 'files', 'need', 'time']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y89RkXPvQlbH"
      },
      "source": [
        "토픽 모델링 알고리즘 \n",
        "\n",
        "• 문서들이 토픽들의 혼합으로 구성되어져 있다고 가졍하며, 토픽들은 확률 분포를 기반으로 단어들이 생성된다고 가정함\n",
        "\n",
        "LDA \n",
        "1. 사용자는 알고리즘에게 토픽의 개수 k를 알려줍니다.\n",
        "2. 모든 단어를 k개 중 하나의 토픽에 할당합니다.\n",
        "3. 어떤 문서의 각 단어 w는 자신은 잘못된 토픽에 할당되어져 있지만, 다른 단어들은 전부 올바른 토픽에 할당되어져 있는 상태라고 가정합니다. 이에 따라 단어 w는 두 가지 기준에 따라서 토픽이 재할당됩니다. (반복)\n",
        "\n",
        "• p(topic t | document d) : 문서 d의 단어들 중 토픽 t에 해당하는 단어들의 비율\n",
        "• p(word w | topic t) : 각 토픽들 t에서 해당 단어 w의 분포"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq6w2oavSnIa",
        "outputId": "3666a4b7-498b-43f5-85be-92c82a142c18"
      },
      "source": [
        "from gensim import corpora\n",
        "\n",
        "dictionary = corpora.Dictionary(tokenized_doc) \n",
        "\n",
        "#각 단어의 (word_id, word_frequency)의 형태를 정수 인코딩 수행\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
        "print(corpus[0]) #단어의 정수 인코딩값과 빈도수\n",
        "print(dictionary[66])  #단어의 정수 인코딩값 , 기존단어 =faith\n",
        "print(len(dictionary))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 4), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1)]\n",
            "faith\n",
            "65284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alo3xHl-TzYC",
        "outputId": "a8837499-d351-4abd-b278-57ce06280f42"
      },
      "source": [
        "import gensim\n",
        "t = 20 #20개의 토픽\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = t, id2word=dictionary, passes=15) #passes는 알고리즘 동작 횟수\n",
        "topics = ldamodel.print_topics(num_words=4)\n",
        "for topic in topics:\n",
        "    print(topic) #토픽에 대한 기여도"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '0.011*\"president\" + 0.009*\"government\" + 0.008*\"states\" + 0.007*\"state\"')\n",
            "(1, '0.009*\"wire\" + 0.008*\"ground\" + 0.007*\"filename\" + 0.006*\"wiring\"')\n",
            "(2, '0.014*\"said\" + 0.010*\"people\" + 0.008*\"know\" + 0.008*\"went\"')\n",
            "(3, '0.019*\"file\" + 0.019*\"output\" + 0.018*\"entry\" + 0.013*\"program\"')\n",
            "(4, '0.007*\"nubus\" + 0.005*\"liar\" + 0.005*\"macs\" + 0.004*\"decenso\"')\n",
            "(5, '0.011*\"would\" + 0.011*\"drive\" + 0.011*\"thanks\" + 0.010*\"know\"')\n",
            "(6, '0.011*\"good\" + 0.009*\"price\" + 0.007*\"like\" + 0.007*\"sale\"')\n",
            "(7, '0.014*\"university\" + 0.011*\"april\" + 0.008*\"center\" + 0.007*\"research\"')\n",
            "(8, '0.008*\"runs\" + 0.008*\"right\" + 0.007*\"left\" + 0.007*\"back\"')\n",
            "(9, '0.016*\"would\" + 0.014*\"people\" + 0.006*\"like\" + 0.006*\"think\"')\n",
            "(10, '0.017*\"armenian\" + 0.016*\"turkish\" + 0.013*\"armenians\" + 0.010*\"turkey\"')\n",
            "(11, '0.012*\"encryption\" + 0.010*\"chip\" + 0.010*\"government\" + 0.010*\"security\"')\n",
            "(12, '0.015*\"israel\" + 0.012*\"jews\" + 0.009*\"israeli\" + 0.009*\"health\"')\n",
            "(13, '0.007*\"science\" + 0.006*\"think\" + 0.005*\"objective\" + 0.005*\"first\"')\n",
            "(14, '0.009*\"pain\" + 0.006*\"soon\" + 0.005*\"gordon\" + 0.004*\"pitt\"')\n",
            "(15, '0.020*\"team\" + 0.018*\"game\" + 0.016*\"games\" + 0.014*\"play\"')\n",
            "(16, '0.038*\"space\" + 0.014*\"nasa\" + 0.008*\"launch\" + 0.007*\"earth\"')\n",
            "(17, '0.016*\"would\" + 0.014*\"think\" + 0.012*\"like\" + 0.011*\"good\"')\n",
            "(18, '0.011*\"file\" + 0.010*\"available\" + 0.009*\"files\" + 0.007*\"information\"')\n",
            "(19, '0.016*\"jesus\" + 0.010*\"christian\" + 0.009*\"bible\" + 0.008*\"church\"')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-9bXK_4UAn3",
        "outputId": "07e056a1-4135-489a-f80c-8546fbcb00a5"
      },
      "source": [
        "#문서 별 토픽 분포\n",
        "\n",
        "for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "    if i==5:\n",
        "        break\n",
        "    print(i,'번째 문서의 topic 비율은',topic_list)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 번째 문서의 topic 비율은 [(9, 0.36643258), (12, 0.4657715), (13, 0.023871293), (15, 0.02057987), (17, 0.11124801)]\n",
            "1 번째 문서의 topic 비율은 [(1, 0.11514453), (8, 0.038037624), (9, 0.18257111), (13, 0.1292207), (14, 0.027046261), (17, 0.34722865), (19, 0.14489748)]\n",
            "2 번째 문서의 topic 비율은 [(1, 0.017270287), (2, 0.2028719), (12, 0.30199325), (13, 0.0757194), (17, 0.39004838)]\n",
            "3 번째 문서의 topic 비율은 [(5, 0.26338184), (7, 0.04114795), (8, 0.016816545), (9, 0.11775025), (11, 0.2989814), (17, 0.25147423)]\n",
            "4 번째 문서의 topic 비율은 [(3, 0.066534124), (15, 0.27009544), (16, 0.20208488), (17, 0.43165594)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjCf2j48X2nx"
      },
      "source": [
        "문서 군집화\n",
        "\n",
        "• 데이터 안에서 숨겨진 구조를 찾는다\n",
        "\n",
        "군집화 알고리즘 - k-means, 밀도 기반의 DBSCAN\n",
        "\n",
        "k-means:  \n",
        "1. 특성 공간 내에 랜덤하게 k개의 좌표점을 초기 클러스터 중심점으로 선택\n",
        "2. 모든 샘플들을 가장 가까운 중심점에 할당\n",
        "3. 할당된 샘플들의 중심으로 centroid의 위치를 update\n",
        "4. 2-3을 반복, 클러스터 할당이 더 이상 변하지 않을 때까지 \n",
        "\n",
        "• 동일한 군집에 속하는 문서를 같은 카테고리 소속으로 분류(텍스트 분류 기반의 문서 분류와 유사)\n",
        "\n",
        "• 텍스트 분류 기반의 문서 분류는 사전에 결정 카테고리 값을 가진 학습 데이터 세트가 필요한 데 반해, 문서 군집화는 학습 데이터 세트가 필요없는 비지도학습 기반으로 동작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_MPOxxnbehY",
        "outputId": "847f9de6-1fa1-47cc-97cf-3236943249b5"
      },
      "source": [
        "#opinion review\n",
        "\n",
        "import os, glob\n",
        "\n",
        "path = '/content/drive/MyDrive/OpinosisDataset1.0/topics'\n",
        "all_files = glob.glob(os.path.join(path, \"*.data\"))\n",
        "filename_list =[]\n",
        "opinion_text = []\n",
        "\n",
        "#여러 개의 파일을 DataFrame으로 읽은 후 다시 문자열로 반환한 뒤 파일 내용 리스트에 추가\n",
        "for file_ in all_files:\n",
        "    df = pd.read_table(file_, index_col=None, header=0, encoding='latin1')\n",
        "    filename_ = file_.split('/')[-1]\n",
        "    filename = filename_.split('.')[0]\n",
        "    filename_list.append(filename)\n",
        "    opinion_text.append(df.to_string())\n",
        "\n",
        "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
        "print(document_df.head())"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          filename                                       opinion_text\n",
            "0           food_swissotel_chicago                                                ...\n",
            "1     display_garmin_nuvi_255W_gps                                                ...\n",
            "2  directions_garmin_nuvi_255W_gps                                                ...\n",
            "3        comfort_toyota_camry_2007                                                ...\n",
            "4        comfort_honda_accord_2008                                                ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFhmapficfdF",
        "outputId": "da37c513-6795-4acd-d6e3-637fb5fa4749"
      },
      "source": [
        "#cleansing, 토큰화, 어근추출, 불용어 제거, 피처 벡터화\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
        "\n",
        "tfodf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english', ngram_range=(1,2), min_df=0.05, max_df=0.85)\n",
        "feature_vect = tfodf_vect.fit_transform(document_df['opinion_text'])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AElNrHXjdzhm",
        "outputId": "95b7600a-33f8-48a6-dcc5-a311654b6fbc"
      },
      "source": [
        "#각 문서별 텍스트가 TF-IDF변환된 피처 벡터화 행렬 데이터에 대해서 군집화를 수행\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "km_cluster = KMeans(n_clusters=5, max_iter=1000, random_state=0)\n",
        "km_cluster.fit(feature_vect)\n",
        "cluster_label = km_cluster.labels_\n",
        "cluster_centers = km_cluster.cluster_centers_\n",
        "\n",
        "document_df['cluster_label'] = cluster_label\n",
        "print(document_df.head())\n",
        "\n",
        "print(document_df[document_df['cluster_label']==0].sort_values(by='filename'))\n",
        "print(document_df[document_df['cluster_label']==1].sort_values(by='filename'))\n",
        "print(document_df[document_df['cluster_label']==2].sort_values(by='filename'))\n",
        "print(document_df[document_df['cluster_label']==3].sort_values(by='filename'))\n",
        "print(document_df[document_df['cluster_label']==4].sort_values(by='filename'))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          filename  ... cluster_label\n",
            "0           food_swissotel_chicago  ...             1\n",
            "1     display_garmin_nuvi_255W_gps  ...             0\n",
            "2  directions_garmin_nuvi_255W_gps  ...             0\n",
            "3        comfort_toyota_camry_2007  ...             3\n",
            "4        comfort_honda_accord_2008  ...             3\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "                           filename  ... cluster_label\n",
            "10    accuracy_garmin_nuvi_255W_gps  ...             0\n",
            "2   directions_garmin_nuvi_255W_gps  ...             0\n",
            "1      display_garmin_nuvi_255W_gps  ...             0\n",
            "32   satellite_garmin_nuvi_255W_gps  ...             0\n",
            "31      screen_garmin_nuvi_255W_gps  ...             0\n",
            "13       speed_garmin_nuvi_255W_gps  ...             0\n",
            "16     updates_garmin_nuvi_255W_gps  ...             0\n",
            "17       voice_garmin_nuvi_255W_gps  ...             0\n",
            "\n",
            "[8 rows x 3 columns]\n",
            "                           filename  ... cluster_label\n",
            "9    bathroom_bestwestern_hotel_sfo  ...             1\n",
            "50          food_holiday_inn_london  ...             1\n",
            "0            food_swissotel_chicago  ...             1\n",
            "11       free_bestwestern_hotel_sfo  ...             1\n",
            "40   location_bestwestern_hotel_sfo  ...             1\n",
            "39      location_holiday_inn_london  ...             1\n",
            "38    parking_bestwestern_hotel_sfo  ...             1\n",
            "33         price_holiday_inn_london  ...             1\n",
            "26          room_holiday_inn_london  ...             1\n",
            "27      rooms_bestwestern_hotel_sfo  ...             1\n",
            "28          rooms_swissotel_chicago  ...             1\n",
            "29    service_bestwestern_hotel_sfo  ...             1\n",
            "23       service_holiday_inn_london  ...             1\n",
            "22  service_swissotel_hotel_chicago  ...             1\n",
            "14      staff_bestwestern_hotel_sfo  ...             1\n",
            "19          staff_swissotel_chicago  ...             1\n",
            "\n",
            "[16 rows x 3 columns]\n",
            "                       filename  ... cluster_label\n",
            "8    battery-life_amazon_kindle  ...             2\n",
            "7    battery-life_ipod_nano_8gb  ...             2\n",
            "6   battery-life_netbook_1005ha  ...             2\n",
            "43      keyboard_netbook_1005ha  ...             2\n",
            "41   performance_netbook_1005ha  ...             2\n",
            "25         screen_ipod_nano_8gb  ...             2\n",
            "24        screen_netbook_1005ha  ...             2\n",
            "21     size_asus_netbook_1005ha  ...             2\n",
            "20          sound_ipod_nano_8gb  ...             2\n",
            "18          video_ipod_nano_8gb  ...             2\n",
            "\n",
            "[10 rows x 3 columns]\n",
            "                          filename  ... cluster_label\n",
            "4        comfort_honda_accord_2008  ...             3\n",
            "3        comfort_toyota_camry_2007  ...             3\n",
            "44   gas_mileage_toyota_camry_2007  ...             3\n",
            "45      interior_honda_accord_2008  ...             3\n",
            "46      interior_toyota_camry_2007  ...             3\n",
            "42       mileage_honda_accord_2008  ...             3\n",
            "37   performance_honda_accord_2008  ...             3\n",
            "34       quality_toyota_camry_2007  ...             3\n",
            "30         seats_honda_accord_2008  ...             3\n",
            "15  transmission_toyota_camry_2007  ...             3\n",
            "\n",
            "[10 rows x 3 columns]\n",
            "                         filename  ... cluster_label\n",
            "5           buttons_amazon_kindle  ...             4\n",
            "48  eyesight-issues_amazon_kindle  ...             4\n",
            "47              features_windows7  ...             4\n",
            "49            fonts_amazon_kindle  ...             4\n",
            "36       navigation_amazon_kindle  ...             4\n",
            "35            price_amazon_kindle  ...             4\n",
            "12                 speed_windows7  ...             4\n",
            "\n",
            "[7 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m3wm4eVXg1yp",
        "outputId": "b12cad61-1e23-4050-b3ea-47bd463b4eb6"
      },
      "source": [
        "#군집화 수 조정\n",
        "km_cluster = KMeans(n_clusters=3, max_iter=1000, random_state=0)\n",
        "km_cluster.fit(feature_vect)\n",
        "cluster_label = km_cluster.labels_\n",
        "cluster_centers = km_cluster.cluster_centers_\n",
        "\n",
        "document_df['cluster_label'] = cluster_label\n",
        "document_df.sort_values(by='cluster_label')\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>opinion_text</th>\n",
              "      <th>cluster_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>performance_honda_accord_2008</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>interior_toyota_camry_2007</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>interior_honda_accord_2008</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>comfort_toyota_camry_2007</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>comfort_honda_accord_2008</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>gas_mileage_toyota_camry_2007</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>mileage_honda_accord_2008</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>transmission_toyota_camry_2007</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>quality_toyota_camry_2007</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>seats_honda_accord_2008</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>room_holiday_inn_london</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>rooms_bestwestern_hotel_sfo</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>rooms_swissotel_chicago</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>service_bestwestern_hotel_sfo</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>food_swissotel_chicago</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>service_holiday_inn_london</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>parking_bestwestern_hotel_sfo</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>location_holiday_inn_london</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>location_bestwestern_hotel_sfo</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>price_holiday_inn_london</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>service_swissotel_hotel_chicago</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>food_holiday_inn_london</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>staff_swissotel_chicago</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>staff_bestwestern_hotel_sfo</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>free_bestwestern_hotel_sfo</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>sound_ipod_nano_8gb</td>\n",
              "      <td>headphone jack i got a clear case for it a...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>eyesight-issues_amazon_kindle</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>features_windows7</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>display_garmin_nuvi_255W_gps</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>directions_garmin_nuvi_255W_gps</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>buttons_amazon_kindle</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>keyboard_netbook_1005ha</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>battery-life_netbook_1005ha</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>performance_netbook_1005ha</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>battery-life_ipod_nano_8gb</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>battery-life_amazon_kindle</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>navigation_amazon_kindle</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>size_asus_netbook_1005ha</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>price_amazon_kindle</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>speed_windows7</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>satellite_garmin_nuvi_255W_gps</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>screen_garmin_nuvi_255W_gps</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>speed_garmin_nuvi_255W_gps</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>updates_garmin_nuvi_255W_gps</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>voice_garmin_nuvi_255W_gps</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>video_ipod_nano_8gb</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>fonts_amazon_kindle</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>screen_netbook_1005ha</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>screen_ipod_nano_8gb</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           filename  ... cluster_label\n",
              "37    performance_honda_accord_2008  ...             0\n",
              "46       interior_toyota_camry_2007  ...             0\n",
              "45       interior_honda_accord_2008  ...             0\n",
              "3         comfort_toyota_camry_2007  ...             0\n",
              "4         comfort_honda_accord_2008  ...             0\n",
              "44    gas_mileage_toyota_camry_2007  ...             0\n",
              "42        mileage_honda_accord_2008  ...             0\n",
              "15   transmission_toyota_camry_2007  ...             0\n",
              "34        quality_toyota_camry_2007  ...             0\n",
              "30          seats_honda_accord_2008  ...             0\n",
              "26          room_holiday_inn_london  ...             1\n",
              "27      rooms_bestwestern_hotel_sfo  ...             1\n",
              "28          rooms_swissotel_chicago  ...             1\n",
              "29    service_bestwestern_hotel_sfo  ...             1\n",
              "0            food_swissotel_chicago  ...             1\n",
              "23       service_holiday_inn_london  ...             1\n",
              "38    parking_bestwestern_hotel_sfo  ...             1\n",
              "39      location_holiday_inn_london  ...             1\n",
              "40   location_bestwestern_hotel_sfo  ...             1\n",
              "33         price_holiday_inn_london  ...             1\n",
              "22  service_swissotel_hotel_chicago  ...             1\n",
              "50          food_holiday_inn_london  ...             1\n",
              "19          staff_swissotel_chicago  ...             1\n",
              "14      staff_bestwestern_hotel_sfo  ...             1\n",
              "11       free_bestwestern_hotel_sfo  ...             1\n",
              "9    bathroom_bestwestern_hotel_sfo  ...             1\n",
              "20              sound_ipod_nano_8gb  ...             2\n",
              "48    eyesight-issues_amazon_kindle  ...             2\n",
              "47                features_windows7  ...             2\n",
              "1      display_garmin_nuvi_255W_gps  ...             2\n",
              "2   directions_garmin_nuvi_255W_gps  ...             2\n",
              "5             buttons_amazon_kindle  ...             2\n",
              "43          keyboard_netbook_1005ha  ...             2\n",
              "6       battery-life_netbook_1005ha  ...             2\n",
              "41       performance_netbook_1005ha  ...             2\n",
              "7        battery-life_ipod_nano_8gb  ...             2\n",
              "8        battery-life_amazon_kindle  ...             2\n",
              "36         navigation_amazon_kindle  ...             2\n",
              "21         size_asus_netbook_1005ha  ...             2\n",
              "35              price_amazon_kindle  ...             2\n",
              "12                   speed_windows7  ...             2\n",
              "32   satellite_garmin_nuvi_255W_gps  ...             2\n",
              "31      screen_garmin_nuvi_255W_gps  ...             2\n",
              "13       speed_garmin_nuvi_255W_gps  ...             2\n",
              "16     updates_garmin_nuvi_255W_gps  ...             2\n",
              "17       voice_garmin_nuvi_255W_gps  ...             2\n",
              "18              video_ipod_nano_8gb  ...             2\n",
              "49              fonts_amazon_kindle  ...             2\n",
              "24            screen_netbook_1005ha  ...             2\n",
              "10    accuracy_garmin_nuvi_255W_gps  ...             2\n",
              "25             screen_ipod_nano_8gb  ...             2\n",
              "\n",
              "[51 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    }
  ]
}