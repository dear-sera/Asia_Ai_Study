{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prj_01_news_category_classification_03_learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5XU2hOwsO4D9TAi0GpemR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sera0911/asia_ai_study/blob/main/New_MachinLearning/prj_01_news_category_classification_03_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCaCEQkdlG1y"
      },
      "source": [
        "## 전처리 데이터를 모델로 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp6lRRdhk05V"
      },
      "source": [
        "#모듈 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF98E5gLk_5M",
        "outputId": "bf2e2e19-bc72-4f2f-80fc-9101584d67e4"
      },
      "source": [
        "#전처리 된 데이터 불러오기\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = np.load('/content/datasets/news_data_max_27_size_24151.npy', allow_pickle=True)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24367, 27)\n",
            "(2708, 27)\n",
            "(24367, 6)\n",
            "(2708, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGYnVm9MmVXT",
        "outputId": "e11b5f27-81ee-42fa-f697-59a7f5966d62"
      },
      "source": [
        "# 모델 생성하기\n",
        "\n",
        "model = Sequential()\n",
        "#Embedding=라벨링 된 데이터를 원 핫 인코딩 해서 벡터라이징역할(단어들간의 수치적인 관계를 형성시켜준다=단어가 같은 의미들이 같은 방향에 있게끔)\n",
        "#뒤에는 단어의 총 개수를 주어야한다(=차원의 수)\n",
        "#output_dim=300,  # 차원 축소 / 차원이 너무 커지면 데이터가 희소해지기 때문에 차원을 300차원으로 제한 (적은 차원에 데이터들을 압축해서 넣음)\n",
        "model.add(Embedding(24151, 300, input_length=27))  #input_length= 문장의 길이를 줘야한다\n",
        "model.add(Conv1D(32, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(MaxPool1D(pool_size=1))\n",
        "model.add(LSTM(128, activation='tanh', return_sequences=True))  #순서가 있는 문장이기에 LSTM을 사용해준다, return_sequences=True면 앞에 학습이 모두 출력되고, false면 맨 끝 하나만 출력\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(64, activation='tanh', return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(64, activation='tanh'))  #return_sequences=디폴트가 false라 LSTM의 마지막 레이어에는 추가안함\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))  #네이버 뉴스 카테고리=6개라서 6\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 27, 300)           7245300   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 27, 32)            48032     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 27, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 27, 128)           82432     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 27, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 27, 64)            49408     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 27, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 7,467,290\n",
            "Trainable params: 7,467,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3U5865_r6qM",
        "outputId": "fd6b1189-b7a7-46e0-a234-c93a9ccc84e1"
      },
      "source": [
        "# 모델 학습 설정\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "fit_hist = model.fit(X_train, Y_train, batch_size=100, epochs=8, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "244/244 [==============================] - 34s 121ms/step - loss: 0.1107 - accuracy: 0.9704 - val_loss: 1.0679 - val_accuracy: 0.7548\n",
            "Epoch 2/8\n",
            "244/244 [==============================] - 28s 115ms/step - loss: 0.0845 - accuracy: 0.9765 - val_loss: 1.1014 - val_accuracy: 0.7563\n",
            "Epoch 3/8\n",
            "244/244 [==============================] - 28s 115ms/step - loss: 0.0669 - accuracy: 0.9821 - val_loss: 1.2946 - val_accuracy: 0.7470\n",
            "Epoch 4/8\n",
            "244/244 [==============================] - 28s 115ms/step - loss: 0.0621 - accuracy: 0.9833 - val_loss: 1.2269 - val_accuracy: 0.7600\n",
            "Epoch 5/8\n",
            "244/244 [==============================] - 28s 114ms/step - loss: 0.0532 - accuracy: 0.9863 - val_loss: 1.2896 - val_accuracy: 0.7548\n",
            "Epoch 6/8\n",
            "244/244 [==============================] - 28s 115ms/step - loss: 0.0438 - accuracy: 0.9872 - val_loss: 1.4263 - val_accuracy: 0.7585\n",
            "Epoch 7/8\n",
            "244/244 [==============================] - 28s 114ms/step - loss: 0.0450 - accuracy: 0.9876 - val_loss: 1.4804 - val_accuracy: 0.7482\n",
            "Epoch 8/8\n",
            "244/244 [==============================] - 28s 113ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 1.5509 - val_accuracy: 0.7312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxdO2NhOx18p",
        "outputId": "6c36ca0c-d4f9-4ba2-af39-54598f866a2b"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print(score[1])  #정확도"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85/85 [==============================] - 1s 12ms/step - loss: 1.5509 - accuracy: 0.7312\n",
            "0.7311668992042542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K00SgfyIw_1u"
      },
      "source": [
        "# 모델 저장하기\n",
        "\n",
        "model.save('/content/models/news_classfication_{}.h5'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
